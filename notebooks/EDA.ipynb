{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e63d745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd().parent\n",
    "DATA = ROOT / \"data\"\n",
    "sys.path.append(str(ROOT / \"functions\"))\n",
    "\n",
    "from categoric_functions import *\n",
    "from numeric_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6f5a33",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bfac5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total shape: (590540, 434)\n"
     ]
    }
   ],
   "source": [
    "train_path = DATA / \"train_merged.csv\"\n",
    "df = pd.read_csv(train_path, low_memory=False)\n",
    "print(f\"Total shape: {df.shape}\")\n",
    "\n",
    "df = df.sort_values('TransactionDT').reset_index(drop=True)\n",
    "split_idx = int(len(df) * 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93f16a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage decreased to 505.96 Mb (67.7% reduction)\n",
      "Memory usage decreased to 128.29 Mb (67.2% reduction)\n"
     ]
    }
   ],
   "source": [
    "train_df = df.iloc[:split_idx].copy()\n",
    "test_df = df.iloc[split_idx:].copy()\n",
    "\n",
    "train_df = reduce_mem_usage(train_df.copy())\n",
    "test_df = reduce_mem_usage(test_df.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6296afcd",
   "metadata": {},
   "source": [
    "# Handling Missing Values\n",
    "\n",
    "Some features have more than 95% missing values. These are redundat for ml models. I am defining a threshold to determine whether features with missing values will remain in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a05b9447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 414 columns with missing values.\n",
      "There are 9 columns with missing percent > 95%\n",
      " Threshold : 95%\n",
      " Dropped feature num : 9\n"
     ]
    }
   ],
   "source": [
    "threshold = 95 \n",
    "high_missing = top_missing_cols(train_df, thresh=threshold)\n",
    "cols_to_drop = high_missing[high_missing['missing_percent'] > threshold]['col'].tolist()\n",
    "\n",
    "train_df = train_df.drop(columns=cols_to_drop)\n",
    "print(f\" Threshold : {threshold}%\\n Dropped feature num : {len(cols_to_drop)}\")\n",
    "\n",
    "test_df = test_df.drop(columns=[c for c in cols_to_drop if c in test_df.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88687132",
   "metadata": {},
   "source": [
    "### Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e349f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution for 'isFraud':\n",
      "isFraud\n",
      "0    455833\n",
      "1     16599\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Percentage:\n",
      "isFraud\n",
      "0    0.964865\n",
      "1    0.035135\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Class distribution for 'isFraud':\")\n",
    "print(train_df['isFraud'].value_counts())\n",
    "print(\"\\nPercentage:\")\n",
    "print(train_df['isFraud'].value_counts(normalize=True))\n",
    "\n",
    "# counts = train_df['isFraud'].value_counts()\n",
    "# percentages = train_df['isFraud'].value_counts(normalize=True) * 100\n",
    "\n",
    "# colors = ['green', 'red'] \n",
    "# bars = plt.bar(counts.index, counts.values, color=colors[:len(counts)])\n",
    "\n",
    "# plt.title('isFraud Class Frequencies')\n",
    "# plt.xlabel('isFraud')\n",
    "# plt.ylabel('Count')\n",
    "# plt.xticks([0, 1])\n",
    "\n",
    "# for bar, perc in zip(bars, percentages):\n",
    "#     plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.05, f'{perc:.1f}%', ha='center', va='bottom')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804d2ef3",
   "metadata": {},
   "source": [
    "It is known which features are categorical. After cleaning up missing values, the remaining features need to be analysed.\n",
    "\n",
    "**Categorical features are initially divided into two groups**:\n",
    "* High cardinality -> 18 features\n",
    "* Ready for analysis -> 24 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6512a7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original categorical features defined: 49\n",
      "Present in dataset after missing value removal: 42\n",
      "Numerical features: 380\n",
      "\n",
      "Categorical features will be tracked and updated throughout this notebook.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Feature Type Definitions (Based on Kaggle Competition Description)\n",
    "# =============================================================================\n",
    "# These lists are based on the IEEE-CIS Fraud Detection competition data description.\n",
    "# We will maintain these lists throughout the notebook, updating them as we:\n",
    "#   - Add new derived features\n",
    "#   - Remove/transform existing features\n",
    "#\n",
    "# Rule: If a feature is NOT in categorical_features, it is considered NUMERICAL.\n",
    "# =============================================================================\n",
    "\n",
    "# Original categorical features as defined in the competition\n",
    "categorical_features = [\n",
    "    # Transaction features\n",
    "    'ProductCD',\n",
    "    # Card features (card1 is high-cardinality ID-like, but categorical)\n",
    "    'card1', 'card2', 'card3', 'card4', 'card5', 'card6',\n",
    "    # Address features\n",
    "    'addr1', 'addr2',\n",
    "    # Email domains\n",
    "    'P_emaildomain', 'R_emaildomain',\n",
    "    # M features (match flags)\n",
    "    'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9',\n",
    "    # Device features\n",
    "    'DeviceType', 'DeviceInfo',\n",
    "    # Identity features (categorical)\n",
    "    'id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18', 'id_19', 'id_20',\n",
    "    'id_21', 'id_22', 'id_23', 'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_29', \n",
    "    'id_30',  # OS version string\n",
    "    'id_31',  # Browser\n",
    "    'id_32',  # Screen resolution (categorical representation)\n",
    "    'id_33',  # Screen resolution string (e.g., \"1920x1080\")\n",
    "    'id_34', 'id_35', 'id_36', 'id_37', 'id_38'\n",
    "]\n",
    "\n",
    "# Keep a copy of the original list for reference\n",
    "ORIGINAL_CATEGORICAL_FEATURES = categorical_features.copy()\n",
    "\n",
    "# Filter to only features present in the dataset\n",
    "present_cat_cols = [col for col in categorical_features if col in train_df.columns]\n",
    "print(f\"Original categorical features defined: {len(ORIGINAL_CATEGORICAL_FEATURES)}\")\n",
    "print(f\"Present in dataset after missing value removal: {len(present_cat_cols)}\")\n",
    "\n",
    "# Update categorical_features to only include present columns\n",
    "categorical_features = present_cat_cols.copy()\n",
    "\n",
    "# Numerical features = everything else (except target and IDs)\n",
    "exclude_cols = ['TransactionID', 'TransactionDT', 'isFraud']\n",
    "numerical_features = [col for col in train_df.columns \n",
    "                      if col not in categorical_features and col not in exclude_cols]\n",
    "\n",
    "print(f\"Numerical features: {len(numerical_features)}\")\n",
    "print(f\"\\nCategorical features will be tracked and updated throughout this notebook.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e265fe95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low cardinality categorical features (<= 15 unique): 24\n",
      "High cardinality categorical features (> 15 unique): 18\n"
     ]
    }
   ],
   "source": [
    "# Separate categorical features by cardinality for different encoding strategies\n",
    "cardinality_threshold = 15\n",
    "\n",
    "low_cardinality_cats = [col for col in categorical_features if col in train_df.columns \n",
    "                        and train_df[col].nunique() <= cardinality_threshold]\n",
    "high_cardinality_cats = [col for col in categorical_features if col in train_df.columns \n",
    "                         and train_df[col].nunique() > cardinality_threshold]\n",
    "\n",
    "print(f\"Low cardinality categorical features (<= {cardinality_threshold} unique): {len(low_cardinality_cats)}\")\n",
    "print(f\"High cardinality categorical features (> {cardinality_threshold} unique): {len(high_cardinality_cats)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f872173",
   "metadata": {},
   "source": [
    "The functions that should be applied for categorical variables are ready, but I want to set them up as a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50aef93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Main pipeline , rare_maps are containing all rare category mappings\n",
    "def apply_categorical_engineering(df, rare_maps=None):\n",
    "    \"\"\"\n",
    "    Complete categorical feature engineering pipeline.\n",
    "    functions chained together.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Rare encoding\n",
    "    df, rare_maps = encode_rare_categories(\n",
    "        df, \n",
    "        columns={'card3': 200, 'card5': 300},\n",
    "        rare_maps=rare_maps\n",
    "    )\n",
    "    \n",
    "    # Domain-specific transformations\n",
    "    df = (df\n",
    "        .pipe(clean_email_domains)\n",
    "        .pipe(create_email_match)\n",
    "        .pipe(consolidate_device_info)\n",
    "        .pipe(extract_screen_features)\n",
    "    )\n",
    "    return df, rare_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d766a5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: encode_rare_categories, extract_screen_features, and create_interaction_features\n",
    "# are already defined in categoric_functions.py and imported at the top of this notebook.\n",
    "# The apply_categorical_engineering pipeline above uses these imported functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2881637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 5 new categorical features\n",
      "Total categorical features now: 47\n"
     ]
    }
   ],
   "source": [
    "# Train set - learn rare categories\n",
    "train_df, rare_maps = apply_categorical_engineering(train_df, rare_maps=None)\n",
    "\n",
    "# Test set - use learned rare categories\n",
    "test_df, _ = apply_categorical_engineering(test_df, rare_maps=rare_maps)\n",
    "\n",
    "\n",
    "new_categorical_features = [\n",
    "    'P_emaildomain_bin',   # Binned email domain (from P_emaildomain)\n",
    "    'R_emaildomain_bin',   # Binned email domain (from R_emaildomain)\n",
    "    'email_match',         # Whether P and R email domains match\n",
    "    'OS_type',             # Extracted OS type (from id_30)\n",
    "    'Device_name',         # Extracted device name (from DeviceInfo)\n",
    "]\n",
    "\n",
    "# Add new categorical features to the list\n",
    "for feat in new_categorical_features:\n",
    "    if feat in train_df.columns and feat not in categorical_features:\n",
    "        categorical_features.append(feat)\n",
    "\n",
    "# Note: screen_width, screen_height, total_pixels, aspect_ratio are NUMERICAL\n",
    "# (extracted from id_33 but represent actual numeric measurements)\n",
    "\n",
    "print(f\"Added {len(new_categorical_features)} new categorical features\")\n",
    "print(f\"Total categorical features now: {len(categorical_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d50dcdeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning 171 feature pairs...\n",
      "Progress: 100/171 pairs processed...\n",
      "\n",
      "Analysis complete! Found 171 valid combinations.\n",
      "Top fraud rate: 98.4%\n",
      "Added 30 interaction features to categorical list\n",
      "Total categorical features now: 77\n"
     ]
    }
   ],
   "source": [
    "categorical_to_scan = [\n",
    "'P_emaildomain_bin', 'R_emaildomain_bin', 'email_match', 'OS_type', 'Device_name',\n",
    "'card5', 'card3', 'card6','card4', 'ProductCD','DeviceType', 'screen_width' , 'screen_height', 'total_pixels' , 'aspect_ratio'\n",
    ", 'id_28' , 'id_20', 'id_15','id_19'\n",
    "]\n",
    "\n",
    "# Step 1: Scan ONLY on train to identify top interactions\n",
    "top_combos = scan_all_bivariate_combinations(\n",
    "    train_df, \n",
    "    feature_list=categorical_to_scan,\n",
    "    target='isFraud',\n",
    "    min_samples=50,\n",
    "    top_n=30\n",
    ")\n",
    "\n",
    "# Step 2: Extract column pairs (without fraud rates)\n",
    "interactions = [\n",
    "    (row['feature1'], row['feature2']) \n",
    "    for _, row in top_combos.iterrows()\n",
    "]\n",
    "\n",
    "# Step 3: Apply SAME interactions to both train and test\n",
    "train_df = create_interaction_features(train_df, interactions)\n",
    "test_df = create_interaction_features(test_df, interactions)\n",
    "\n",
    "\n",
    "# update categorical_features list --> insert interactions.\n",
    "interaction_feature_names = [f\"inter_{col1}_x_{col2}\" for col1, col2 in interactions]\n",
    "\n",
    "for feat in interaction_feature_names:\n",
    "    if feat in train_df.columns and feat not in categorical_features:\n",
    "        categorical_features.append(feat)\n",
    "\n",
    "print(f\"Added {len(interaction_feature_names)} interaction features to categorical list\")\n",
    "print(f\"Total categorical features now: {len(categorical_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ef2b9a",
   "metadata": {},
   "source": [
    "Some features have become unnecessary after the transformation, and this is certain..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ad0c174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 5 transformed features from categorical list\n",
      "Total categorical features now: 72\n"
     ]
    }
   ],
   "source": [
    "drop_cols = [\n",
    "    'P_emaildomain',      # replaced by P_emaildomain_bin\n",
    "    'R_emaildomain',      # replaced by R_emaildomain_bin\n",
    "    'id_30',              # replaced by OS_type\n",
    "    'DeviceInfo',         # replaced by Device_name\n",
    "    'id_33',              # replaced by screen_width, screen_height, etc.\n",
    "]\n",
    "\n",
    "train_df = train_df.drop(columns=drop_cols, errors='ignore')\n",
    "test_df = test_df.drop(columns=drop_cols, errors='ignore')\n",
    "\n",
    "# update the list\n",
    "for col in drop_cols:\n",
    "    if col in categorical_features:\n",
    "        categorical_features.remove(col)\n",
    "\n",
    "print(f\"Removed {len(drop_cols)} transformed features from categorical list\")\n",
    "print(f\"Total categorical features now: {len(categorical_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2b9d7d",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c427ccbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features to encode: 61\n",
      "\n",
      "Low Cardinality (Label Encoding): 29\n",
      "['ProductCD', 'card3', 'card4', 'card6', 'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'id_12', 'id_15', 'id_16', 'id_28', 'id_29', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38', 'DeviceType', 'P_emaildomain_bin', 'R_emaildomain_bin', 'email_match', 'OS_type', 'Device_name']\n",
      "\n",
      "High Cardinality (Frequency Encoding): 32\n",
      "['card5', 'id_31', 'inter_card3_x_id_19', 'inter_Device_name_x_card3', 'inter_R_emaildomain_bin_x_aspect_ratio', 'inter_R_emaildomain_bin_x_screen_height', 'inter_R_emaildomain_bin_x_total_pixels', 'inter_ProductCD_x_aspect_ratio', 'inter_ProductCD_x_total_pixels', 'inter_ProductCD_x_screen_height', 'inter_P_emaildomain_bin_x_screen_height', 'inter_P_emaildomain_bin_x_total_pixels', 'inter_P_emaildomain_bin_x_aspect_ratio', 'inter_P_emaildomain_bin_x_id_19', 'inter_R_emaildomain_bin_x_id_19', 'inter_aspect_ratio_x_id_28', 'inter_aspect_ratio_x_id_15', 'inter_email_match_x_screen_width', 'inter_email_match_x_total_pixels', 'inter_id_20_x_id_19', 'inter_total_pixels_x_id_28', 'inter_screen_height_x_id_15', 'inter_card6_x_total_pixels', 'inter_card6_x_screen_width', 'inter_total_pixels_x_id_15', 'inter_screen_height_x_id_20', 'inter_screen_height_x_id_28', 'inter_aspect_ratio_x_id_20', 'inter_card6_x_aspect_ratio', 'inter_email_match_x_screen_height', 'inter_total_pixels_x_id_20', 'inter_card6_x_screen_height']\n",
      "Categorical features (tracked): 72\n"
     ]
    }
   ],
   "source": [
    "# We use the tracked categorical_features list to identify what needs encoding\n",
    "\n",
    "\n",
    "object_columns = [col for col in train_df.select_dtypes(include=['object']).columns \n",
    "                  if col in categorical_features]\n",
    "\n",
    "print(f\"Categorical features to encode: {len(object_columns)}\")\n",
    "\n",
    "# Separate by cardinality for different encoding strategies\n",
    "cardinality_threshold = 15\n",
    "low_cardinality_objects = [col for col in object_columns \n",
    "                           if train_df[col].nunique() <= cardinality_threshold]\n",
    "high_cardinality_objects = [col for col in object_columns \n",
    "                            if train_df[col].nunique() > cardinality_threshold]\n",
    "\n",
    "print(f\"\\nLow Cardinality (Label Encoding): {len(low_cardinality_objects)}\")\n",
    "print(low_cardinality_objects)\n",
    "\n",
    "print(f\"\\nHigh Cardinality (Frequency Encoding): {len(high_cardinality_objects)}\")\n",
    "print(high_cardinality_objects)\n",
    "\n",
    "# Frequency encoding for high cardinality\n",
    "train_df, freq_maps = apply_frequency_encoding(train_df, high_cardinality_objects, normalize=True)\n",
    "test_df, _ = apply_frequency_encoding(test_df, high_cardinality_objects, freq_dict=freq_maps)\n",
    "\n",
    "# Label encoding for low cardinality\n",
    "train_df, label_encoders = apply_label_encoding(train_df, low_cardinality_objects)\n",
    "test_df, _ = apply_label_encoding(test_df, low_cardinality_objects, encoder_dict=label_encoders)\n",
    "\n",
    "\n",
    "print(f\"Categorical features (tracked): {len(categorical_features)}\")\n",
    "# print(f\"These will be EXCLUDED from numerical feature analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ea7b35",
   "metadata": {},
   "source": [
    "**IMPORTANT NOTE ON ENCODED FEATURES**:\n",
    "\n",
    "After encoding, categorical features become numeric in dtype, BUT they are \n",
    "still conceptually categorical. We keep them in categorical_features list\n",
    "to distinguish them from originally numerical features during analysis.\n",
    "\n",
    "For KS test on numerical features, we will EXCLUDE categorical_features\n",
    "even though they are now encoded as numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8222ffee",
   "metadata": {},
   "source": [
    "#### Evaluate the feature importance (categoric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e81e619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Feature Importance (Single-Feature AUC):\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Feature",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "AUC",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "938ed8aa-7a9f-4ef6-8ae7-291257f86966",
       "rows": [
        [
         "2",
         "card2",
         "0.7349120465995789"
        ],
        [
         "26",
         "id_19",
         "0.7224741442853702"
        ],
        [
         "27",
         "id_20",
         "0.7095965858850716"
        ],
        [
         "54",
         "inter_R_emaildomain_bin_x_id_19",
         "0.70422851185363"
        ],
        [
         "53",
         "inter_P_emaildomain_bin_x_id_19",
         "0.6996784042935912"
        ],
        [
         "1",
         "card1",
         "0.6969830943518132"
        ],
        [
         "42",
         "inter_card3_x_id_19",
         "0.6964047568702599"
        ],
        [
         "46",
         "inter_R_emaildomain_bin_x_total_pixels",
         "0.6931953128785711"
        ],
        [
         "45",
         "inter_R_emaildomain_bin_x_screen_height",
         "0.6911050835884675"
        ],
        [
         "48",
         "inter_ProductCD_x_total_pixels",
         "0.6909169702576301"
        ],
        [
         "67",
         "inter_aspect_ratio_x_id_20",
         "0.6896939252439372"
        ],
        [
         "70",
         "inter_total_pixels_x_id_20",
         "0.6888204371416193"
        ],
        [
         "49",
         "inter_ProductCD_x_screen_height",
         "0.6885448323458366"
        ],
        [
         "64",
         "inter_total_pixels_x_id_15",
         "0.6882051570082891"
        ],
        [
         "60",
         "inter_total_pixels_x_id_28",
         "0.6878108778808104"
        ],
        [
         "65",
         "inter_screen_height_x_id_20",
         "0.6876515348413765"
        ],
        [
         "61",
         "inter_screen_height_x_id_15",
         "0.6873784549532682"
        ],
        [
         "66",
         "inter_screen_height_x_id_28",
         "0.6865107259017791"
        ],
        [
         "44",
         "inter_R_emaildomain_bin_x_aspect_ratio",
         "0.6846856221962805"
        ],
        [
         "59",
         "inter_id_20_x_id_19",
         "0.684248268393501"
        ],
        [
         "55",
         "inter_aspect_ratio_x_id_28",
         "0.6818844401371482"
        ],
        [
         "43",
         "inter_Device_name_x_card3",
         "0.6818199466972092"
        ],
        [
         "56",
         "inter_aspect_ratio_x_id_15",
         "0.6816789461318769"
        ],
        [
         "47",
         "inter_ProductCD_x_aspect_ratio",
         "0.6803879246418948"
        ],
        [
         "58",
         "inter_email_match_x_total_pixels",
         "0.6799481164144697"
        ],
        [
         "30",
         "id_31",
         "0.6778880120114831"
        ],
        [
         "0",
         "ProductCD",
         "0.6776677261146965"
        ],
        [
         "69",
         "inter_email_match_x_screen_height",
         "0.6775535480128926"
        ],
        [
         "57",
         "inter_email_match_x_screen_width",
         "0.6762556867323039"
        ],
        [
         "38",
         "R_emaildomain_bin",
         "0.6727873343465269"
        ],
        [
         "33",
         "id_35",
         "0.6719595588937102"
        ],
        [
         "12",
         "M4",
         "0.6715352752876221"
        ],
        [
         "22",
         "id_15",
         "0.6685709844863916"
        ],
        [
         "29",
         "id_29",
         "0.6674888218321183"
        ],
        [
         "28",
         "id_28",
         "0.6667963914157544"
        ],
        [
         "18",
         "DeviceType",
         "0.6625353846831566"
        ],
        [
         "36",
         "id_38",
         "0.6624451017965831"
        ],
        [
         "14",
         "M6",
         "0.6608015293348898"
        ],
        [
         "34",
         "id_36",
         "0.6573494401738582"
        ],
        [
         "35",
         "id_37",
         "0.6571539576954987"
        ],
        [
         "39",
         "email_match",
         "0.6566923254260185"
        ],
        [
         "62",
         "inter_card6_x_total_pixels",
         "0.6565770871419866"
        ],
        [
         "71",
         "inter_card6_x_screen_height",
         "0.6561690205061562"
        ],
        [
         "19",
         "id_12",
         "0.6546815180282373"
        ],
        [
         "63",
         "inter_card6_x_screen_width",
         "0.654364601367077"
        ],
        [
         "24",
         "id_17",
         "0.6511492601209972"
        ],
        [
         "23",
         "id_16",
         "0.648429376739132"
        ],
        [
         "68",
         "inter_card6_x_aspect_ratio",
         "0.6465926800437581"
        ],
        [
         "5",
         "card5",
         "0.6447363354698502"
        ],
        [
         "3",
         "card3",
         "0.6404660029514768"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 72
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>card2</td>\n",
       "      <td>0.734912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>id_19</td>\n",
       "      <td>0.722474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>id_20</td>\n",
       "      <td>0.709597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>inter_R_emaildomain_bin_x_id_19</td>\n",
       "      <td>0.704229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>inter_P_emaildomain_bin_x_id_19</td>\n",
       "      <td>0.699678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>OS_type</td>\n",
       "      <td>0.529030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>M5</td>\n",
       "      <td>0.527613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>id_34</td>\n",
       "      <td>0.519564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>addr2</td>\n",
       "      <td>0.513563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>card4</td>\n",
       "      <td>0.508332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Feature       AUC\n",
       "2                             card2  0.734912\n",
       "26                            id_19  0.722474\n",
       "27                            id_20  0.709597\n",
       "54  inter_R_emaildomain_bin_x_id_19  0.704229\n",
       "53  inter_P_emaildomain_bin_x_id_19  0.699678\n",
       "..                              ...       ...\n",
       "40                          OS_type  0.529030\n",
       "13                               M5  0.527613\n",
       "32                            id_34  0.519564\n",
       "8                             addr2  0.513563\n",
       "4                             card4  0.508332\n",
       "\n",
       "[72 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Test categorical features after encoding\n",
    "# categorical_auc_results = []\n",
    "\n",
    "# for feat in categorical_features:\n",
    "#     if feat in train_df.columns:\n",
    "#         try:\n",
    "#             auc = test_single_feature(train_df, feat, target='isFraud')\n",
    "#             categorical_auc_results.append({'Feature': feat, 'AUC': auc})\n",
    "#         except:\n",
    "#             continue\n",
    "\n",
    "# cat_auc_df = pd.DataFrame(categorical_auc_results).sort_values('AUC', ascending=False)\n",
    "# print(\"Categorical Feature Importance (Single-Feature AUC):\")\n",
    "# display(cat_auc_df)\n",
    "\n",
    "# # Classification \n",
    "# strong_cat = cat_auc_df[cat_auc_df['AUC'] >= 0.60]['Feature'].tolist()  # Better than random\n",
    "# moderate_cat = cat_auc_df[(cat_auc_df['AUC'] >= 0.52) & (cat_auc_df['AUC'] < 0.55)]['Feature'].tolist()\n",
    "# weak_cat = cat_auc_df[cat_auc_df['AUC'] < 0.52]['Feature'].tolist()  # Nearly random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7065c270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "65\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['card2', 'id_19', 'id_20', 'inter_R_emaildomain_bin_x_id_19']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "strong_cat = cat_auc_df[cat_auc_df['AUC'] >= 0.70]['Feature'].tolist()  # Better than random\n",
    "moderate_cat = cat_auc_df[(cat_auc_df['AUC'] >= 0.52) & (cat_auc_df['AUC'] < 0.70)]['Feature'].tolist()\n",
    "weak_cat = cat_auc_df[cat_auc_df['AUC'] < 0.52]['Feature'].tolist()  # Nearly random\n",
    "\n",
    "print(len(weak_cat))\n",
    "print(len(moderate_cat))\n",
    "print(len(strong_cat))\n",
    "strong_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e03d3b4",
   "metadata": {},
   "source": [
    " # Numerical Features\n",
    "\n",
    " The most notable aspect of the numerical features we have is, of course, their size :) The raw dataset contains 383 numerical features.\n",
    "\n",
    "The vast majority of numerical features are “V_” features derived by Vesta Engineering. Dimension reduction methods should be used for these features, whose names are hidden.\n",
    "\n",
    "* The group_by_missing_pattern and test_feature_discrimination functions will be used for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ad1a2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_cols = [col for col in train_df[numerical_features].columns if col.startswith('V')] \n",
    "c_cols = [col for col in train_df[numerical_features].columns if col.startswith('C')]\n",
    "d_cols = [col for col in train_df[numerical_features].columns if col.startswith('D')]\n",
    "id_cols = [col for col in train_df[numerical_features].columns if col.startswith('id_')]\n",
    "\n",
    "grouped_cols = set(v_cols + c_cols + d_cols + id_cols) # bunlardan olmayanları bulmak için\n",
    "\n",
    "indep_cols = [col for col in train_df[numerical_features].columns if col not in grouped_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab0c72f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v_missing = train_df[v_cols].isnull()\n",
    "\n",
    "# missing_rates = v_missing.mean().sort_values(ascending=False)\n",
    "\n",
    "# plt.figure(figsize=(20, 6))\n",
    "# missing_rates.plot(kind='bar')\n",
    "# plt.title('V Sütunları Missing Rates')\n",
    "# plt.ylabel('Missing Rate')\n",
    "# plt.xlabel('V Columns')\n",
    "# plt.axhline(0.5, color='red', linestyle='--', label='50% threshold')\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89493b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Representatives Summary\n",
      "--------------------------------\n",
      "Original V columns: 339\n",
      "Selected representatives: 14\n",
      "Reduction: 95.9%\n",
      "\n",
      "Final shapes:\n",
      "  Train: (472432, 134)\n",
      "  Test: (118108, 134)\n"
     ]
    }
   ],
   "source": [
    "v_pattern_groups = group_by_missing_pattern(train_df, v_cols)\n",
    "\n",
    "representative_v = []\n",
    "\n",
    "for pattern_id, info in v_pattern_groups.items():\n",
    "    group_cols = info['columns']\n",
    "\n",
    "    if len(group_cols) == 1:\n",
    "        representative_v.extend(group_cols)\n",
    "        continue\n",
    "\n",
    "    ks_res = test_feature_discrimination(train_df, group_cols, test='ks')\n",
    "\n",
    "    if not ks_res.empty:\n",
    "        best = ks_res.iloc[0]['Feature']\n",
    "        representative_v.append(best)\n",
    "\n",
    "print(\"Selected Representatives Summary\")\n",
    "print(\"--------------------------------\")\n",
    "print(f\"Original V columns: {len(v_cols)}\")\n",
    "print(f\"Selected representatives: {len(representative_v)}\")\n",
    "print(f\"Reduction: {(1 - len(representative_v)/len(v_cols)) * 100:.1f}%\")\n",
    "\n",
    "# V sütunlarını filtrele - HEM TRAIN HEM TEST\n",
    "cols_to_keep = train_df.columns.difference(v_cols).union(pd.Index(representative_v))\n",
    "train_df = train_df[cols_to_keep]\n",
    "test_df = test_df[[c for c in cols_to_keep if c in test_df.columns]]\n",
    "\n",
    "# v_cols listesini güncelle\n",
    "v_cols = [col for col in train_df.columns if col.startswith('V')]\n",
    "\n",
    "print(f\"\\nFinal shapes:\")\n",
    "print(f\"  Train: {train_df.shape}\")\n",
    "print(f\"  Test: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f2919fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Time baseline first\n",
    "train_df = convert_dt_to_day(train_df)\n",
    "test_df = convert_dt_to_day(test_df)\n",
    "\n",
    "# 2. Create UID (needs D1 in original form!)\n",
    "train_df = create_uid(train_df, uid_cols=['card1', 'addr1', 'D1'])\n",
    "test_df = create_uid(test_df, uid_cols=['card1', 'addr1', 'D1'])\n",
    "\n",
    "# 2.5 D COLS DA MISIING PATTERN\n",
    "train_df = create_d_null_features(train_df, d_cols)\n",
    "test_df = create_d_null_features(test_df, d_cols)\n",
    "\n",
    "train_df = create_d_ratio_and_diff(train_df)\n",
    "test_df = create_d_ratio_and_diff(test_df)\n",
    "\n",
    "# 3. NOW normalize D columns (after UID creation)\n",
    "train_df = normalize_d_columns(train_df)\n",
    "test_df = normalize_d_columns(test_df)\n",
    "\n",
    "# 4. Amount features\n",
    "train_df = extract_amt_decimal(train_df)\n",
    "test_df = extract_amt_decimal(test_df)\n",
    "\n",
    "# 5. Apply log transform to TransactionAmt\n",
    "train_df['TransactionAmt_log'] = np.log1p(train_df['TransactionAmt'])\n",
    "test_df['TransactionAmt_log'] = np.log1p(test_df['TransactionAmt'])\n",
    "\n",
    "# 6. C velocity features\n",
    "train_df = create_c_velocity_features(train_df)\n",
    "test_df = create_c_velocity_features(test_df)\n",
    "\n",
    "# 7. UID aggregations - FIXED: Learn from train, apply to test\n",
    "train_df, uid_agg_maps = create_uid_aggregations(train_df, uid_col='uid')\n",
    "test_df, _ = create_uid_aggregations(test_df, uid_col='uid', agg_maps=uid_agg_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8cc06b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total numeric-type columns in df: 194\n",
      "Tracked categorical features (excluded): 72\n",
      "Exclude columns: ['TransactionID', 'TransactionDT', 'isFraud', 'uid']\n",
      "\n",
      ">>> NUMERICAL FEATURES FOR ANALYSIS: 119 <<<\n",
      "\n",
      "Encoded categoricals correctly excluded: 72\n",
      "Examples: ['ProductCD', 'card1', 'card2', 'card3', 'card4']\n"
     ]
    }
   ],
   "source": [
    "exclude_cols = ['TransactionID', 'TransactionDT', 'isFraud', 'uid']\n",
    "\n",
    "# Get all numeric-type columns\n",
    "all_numeric_cols = train_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Filter: must NOT be in categorical_features and NOT in exclude_cols\n",
    "numerical_features = [col for col in all_numeric_cols \n",
    "                      if col not in categorical_features and col not in exclude_cols]\n",
    "\n",
    "print(f\"Total numeric-type columns in df: {len(all_numeric_cols)}\")\n",
    "print(f\"Tracked categorical features (excluded): {len(categorical_features)}\")\n",
    "print(f\"Exclude columns: {exclude_cols}\")\n",
    "print(f\"\\n>>> NUMERICAL FEATURES FOR ANALYSIS: {len(numerical_features)} <<<\")\n",
    "\n",
    "# Sanity check: show some encoded categoricals that would have been incorrectly included\n",
    "encoded_cats_in_numeric = [col for col in categorical_features \n",
    "                           if col in all_numeric_cols]\n",
    "if encoded_cats_in_numeric:\n",
    "    print(f\"\\nEncoded categoricals correctly excluded: {len(encoded_cats_in_numeric)}\")\n",
    "    print(f\"Examples: {encoded_cats_in_numeric[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42a77d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Features Breakdown:\n",
      "  V columns (Vesta engineered): 14\n",
      "  C columns (counting features): 24\n",
      "  D columns (timedelta features): 58\n",
      "  Engineered numericals: 44\n",
      "  Other original numericals: 12\n",
      "\n",
      "  TOTAL: 119\n",
      "\n",
      "These 119 features will be used for KS discrimination test.\n"
     ]
    }
   ],
   "source": [
    "# Group numerical features by their prefix for better understanding\n",
    "v_cols = [col for col in numerical_features if col.startswith('V')]\n",
    "c_cols = [col for col in numerical_features if col.startswith('C')]\n",
    "d_cols = [col for col in numerical_features if col.startswith('D')]\n",
    "\n",
    "# Engineered numerical features (created during this notebook)\n",
    "engineered_num = [col for col in numerical_features \n",
    "                  if any(x in col for x in ['_log', '_decimal', '_cents', '_ratio', \n",
    "                                            '_mean', '_std', '_normalized', 'Day',\n",
    "                                            'screen_width', 'screen_height', \n",
    "                                            'total_pixels', 'aspect_ratio'])]\n",
    "\n",
    "# Other original numerical features\n",
    "other_num = [col for col in numerical_features \n",
    "             if col not in v_cols + c_cols + d_cols + engineered_num]\n",
    "\n",
    "print(\"Numerical Features Breakdown:\")\n",
    "print(f\"  V columns (Vesta engineered): {len(v_cols)}\")\n",
    "print(f\"  C columns (counting features): {len(c_cols)}\")\n",
    "print(f\"  D columns (timedelta features): {len(d_cols)}\")\n",
    "print(f\"  Engineered numericals: {len(engineered_num)}\")\n",
    "print(f\"  Other original numericals: {len(other_num)}\")\n",
    "print(f\"\\n  TOTAL: {len(numerical_features)}\")\n",
    "\n",
    "# These are the features we'll run KS test on\n",
    "print(f\"\\nThese {len(numerical_features)} features will be used for KS discrimination test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f74a62a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Feature",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Test_Stat",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "P_Value",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Significance",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "n_fraud",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "n_normal",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Unique_Ratio_Fraud",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Unique_Ratio_Normal",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "0d73f38f-a024-4025-bb3e-3f393bacaf16",
       "rows": [
        [
         "0",
         "D5",
         "0.4414",
         "0.0",
         "***",
         "8569",
         "210018",
         "0.036",
         "0.003"
        ],
        [
         "1",
         "D8_normalized",
         "0.3785",
         "0.0",
         "***",
         "6247",
         "55363",
         "0.999",
         "0.994"
        ],
        [
         "2",
         "D3",
         "0.3684",
         "0.0",
         "***",
         "7598",
         "247182",
         "0.031",
         "0.002"
        ],
        [
         "3",
         "D2",
         "0.3318",
         "0.0",
         "***",
         "6296",
         "234873",
         "0.079",
         "0.003"
        ],
        [
         "4",
         "D8",
         "0.3102",
         "0.0",
         "***",
         "6247",
         "55363",
         "0.18",
         "0.093"
        ],
        [
         "5",
         "D9_normalized",
         "0.3087",
         "0.0",
         "***",
         "6247",
         "55363",
         "0.999",
         "0.977"
        ],
        [
         "6",
         "D2_normalized",
         "0.296",
         "0.0",
         "***",
         "6296",
         "234873",
         "0.999",
         "0.997"
        ],
        [
         "7",
         "D15_uid_mean",
         "0.2958",
         "0.0",
         "***",
         "15333",
         "433855",
         "0.165",
         "0.017"
        ],
        [
         "8",
         "D7",
         "0.2895",
         "0.0",
         "***",
         "4482",
         "25462",
         "0.047",
         "0.022"
        ],
        [
         "9",
         "D2_uid_mean",
         "0.2738",
         "0.0",
         "***",
         "13210",
         "366385",
         "0.051",
         "0.006"
        ],
        [
         "10",
         "D12_is_null",
         "0.2586",
         "0.0",
         "***",
         "16599",
         "455833",
         "0.0",
         "0.0"
        ],
        [
         "11",
         "D2_D3_diff",
         "0.2553",
         "0.0",
         "***",
         "5829",
         "227970",
         "0.082",
         "0.003"
        ],
        [
         "12",
         "D9_is_null",
         "0.2549",
         "0.0",
         "***",
         "16599",
         "455833",
         "0.0",
         "0.0"
        ],
        [
         "13",
         "D8_is_null",
         "0.2549",
         "0.0",
         "***",
         "16599",
         "455833",
         "0.0",
         "0.0"
        ],
        [
         "14",
         "D10",
         "0.2518",
         "0.0",
         "***",
         "13311",
         "392730",
         "0.043",
         "0.002"
        ],
        [
         "15",
         "D6_is_null",
         "0.2483",
         "0.0",
         "***",
         "16599",
         "455833",
         "0.0",
         "0.0"
        ],
        [
         "16",
         "D14_is_null",
         "0.2473",
         "0.0",
         "***",
         "16599",
         "455833",
         "0.0",
         "0.0"
        ],
        [
         "17",
         "D15",
         "0.2414",
         "0.0",
         "***",
         "12950",
         "381717",
         "0.046",
         "0.002"
        ],
        [
         "18",
         "D_null_count",
         "0.2315",
         "0.0",
         "***",
         "16599",
         "455833",
         "0.001",
         "0.0"
        ],
        [
         "19",
         "D15_normalized",
         "0.2259",
         "0.0",
         "***",
         "12950",
         "381717",
         "0.999",
         "0.992"
        ],
        [
         "20",
         "D1_normalized",
         "0.2247",
         "0.0",
         "***",
         "16572",
         "454924",
         "0.999",
         "0.987"
        ],
        [
         "21",
         "D13_is_null",
         "0.2245",
         "0.0",
         "***",
         "16599",
         "455833",
         "0.0",
         "0.0"
        ],
        [
         "22",
         "D11_is_null",
         "0.2168",
         "0.0",
         "***",
         "16599",
         "455833",
         "0.0",
         "0.0"
        ],
        [
         "23",
         "D15_uid_std",
         "0.2168",
         "0.0",
         "***",
         "12965",
         "292922",
         "0.186",
         "0.041"
        ],
        [
         "24",
         "D7_is_null",
         "0.2142",
         "0.0",
         "***",
         "16599",
         "455833",
         "0.0",
         "0.0"
        ],
        [
         "25",
         "D7_normalized",
         "0.211",
         "0.0",
         "***",
         "4482",
         "25462",
         "1.0",
         "0.999"
        ],
        [
         "26",
         "D10_normalized",
         "0.2092",
         "0.0",
         "***",
         "13311",
         "392730",
         "0.999",
         "0.991"
        ],
        [
         "27",
         "D1",
         "0.2025",
         "0.0",
         "***",
         "16572",
         "454924",
         "0.033",
         "0.001"
        ],
        [
         "28",
         "D4",
         "0.1891",
         "0.0",
         "***",
         "11537",
         "321121",
         "0.049",
         "0.002"
        ],
        [
         "29",
         "D1_D4_ratio",
         "0.1859",
         "0.0",
         "***",
         "6195",
         "191680",
         "0.234",
         "0.059"
        ],
        [
         "30",
         "D4_normalized",
         "0.1664",
         "0.0",
         "***",
         "11537",
         "321121",
         "0.999",
         "0.992"
        ],
        [
         "31",
         "D10_D15_ratio",
         "0.163",
         "0.0",
         "***",
         "6508",
         "244663",
         "0.161",
         "0.044"
        ],
        [
         "32",
         "D11_normalized",
         "0.1587",
         "0.0",
         "***",
         "4484",
         "221975",
         "0.998",
         "0.994"
        ],
        [
         "33",
         "D11",
         "0.1554",
         "0.0",
         "***",
         "4484",
         "221975",
         "0.11",
         "0.003"
        ],
        [
         "34",
         "D5_normalized",
         "0.155",
         "0.0",
         "***",
         "8569",
         "210018",
         "0.998",
         "0.993"
        ],
        [
         "35",
         "D14",
         "0.1523",
         "0.0",
         "***",
         "5712",
         "44124",
         "0.058",
         "0.017"
        ],
        [
         "36",
         "D2_is_null",
         "0.136",
         "0.0",
         "***",
         "16599",
         "455833",
         "0.0",
         "0.0"
        ],
        [
         "37",
         "D6_normalized",
         "0.1243",
         "0.0",
         "***",
         "6031",
         "52452",
         "1.0",
         "0.998"
        ],
        [
         "38",
         "D13_normalized",
         "0.1224",
         "0.0",
         "***",
         "5317",
         "43656",
         "1.0",
         "0.998"
        ],
        [
         "39",
         "D9",
         "0.1212",
         "0.0",
         "***",
         "6247",
         "55363",
         "0.004",
         "0.0"
        ],
        [
         "40",
         "D3_normalized",
         "0.1182",
         "0.0",
         "***",
         "7598",
         "247182",
         "0.999",
         "0.991"
        ],
        [
         "41",
         "D12",
         "0.1167",
         "0.0",
         "***",
         "5993",
         "46710",
         "0.055",
         "0.013"
        ],
        [
         "42",
         "D14_normalized",
         "0.0937",
         "0.0",
         "***",
         "5712",
         "44124",
         "1.0",
         "0.998"
        ],
        [
         "43",
         "D6",
         "0.092",
         "0.0",
         "***",
         "6031",
         "52452",
         "0.056",
         "0.015"
        ],
        [
         "44",
         "D12_normalized",
         "0.0875",
         "0.0",
         "***",
         "5993",
         "46710",
         "1.0",
         "0.998"
        ],
        [
         "45",
         "D3_is_null",
         "0.0845",
         "0.0",
         "***",
         "16599",
         "455833",
         "0.0",
         "0.0"
        ],
        [
         "46",
         "D2_D3_ratio",
         "0.0787",
         "0.0",
         "***",
         "3191",
         "187582",
         "0.368",
         "0.04"
        ],
        [
         "47",
         "D10_is_null",
         "0.0596",
         "0.0",
         "***",
         "16599",
         "455833",
         "0.0",
         "0.0"
        ],
        [
         "48",
         "D10_D15_diff",
         "0.0584",
         "0.0",
         "***",
         "12643",
         "377036",
         "0.042",
         "0.003"
        ],
        [
         "49",
         "D15_is_null",
         "0.0572",
         "0.0",
         "***",
         "16599",
         "455833",
         "0.0",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 58
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Test_Stat</th>\n",
       "      <th>P_Value</th>\n",
       "      <th>Significance</th>\n",
       "      <th>n_fraud</th>\n",
       "      <th>n_normal</th>\n",
       "      <th>Unique_Ratio_Fraud</th>\n",
       "      <th>Unique_Ratio_Normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D5</td>\n",
       "      <td>0.4414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>8569</td>\n",
       "      <td>210018</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D8_normalized</td>\n",
       "      <td>0.3785</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>6247</td>\n",
       "      <td>55363</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D3</td>\n",
       "      <td>0.3684</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>7598</td>\n",
       "      <td>247182</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D2</td>\n",
       "      <td>0.3318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>6296</td>\n",
       "      <td>234873</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D8</td>\n",
       "      <td>0.3102</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>6247</td>\n",
       "      <td>55363</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>D9_normalized</td>\n",
       "      <td>0.3087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>6247</td>\n",
       "      <td>55363</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>D2_normalized</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>6296</td>\n",
       "      <td>234873</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>D15_uid_mean</td>\n",
       "      <td>0.2958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>15333</td>\n",
       "      <td>433855</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>D7</td>\n",
       "      <td>0.2895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>4482</td>\n",
       "      <td>25462</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>D2_uid_mean</td>\n",
       "      <td>0.2738</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>13210</td>\n",
       "      <td>366385</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>D12_is_null</td>\n",
       "      <td>0.2586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>16599</td>\n",
       "      <td>455833</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>D2_D3_diff</td>\n",
       "      <td>0.2553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>5829</td>\n",
       "      <td>227970</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>D9_is_null</td>\n",
       "      <td>0.2549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>16599</td>\n",
       "      <td>455833</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>D8_is_null</td>\n",
       "      <td>0.2549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>16599</td>\n",
       "      <td>455833</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>D10</td>\n",
       "      <td>0.2518</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>13311</td>\n",
       "      <td>392730</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>D6_is_null</td>\n",
       "      <td>0.2483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>16599</td>\n",
       "      <td>455833</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>D14_is_null</td>\n",
       "      <td>0.2473</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>16599</td>\n",
       "      <td>455833</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>D15</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>12950</td>\n",
       "      <td>381717</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>D_null_count</td>\n",
       "      <td>0.2315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>16599</td>\n",
       "      <td>455833</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>D15_normalized</td>\n",
       "      <td>0.2259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>12950</td>\n",
       "      <td>381717</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>D1_normalized</td>\n",
       "      <td>0.2247</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>16572</td>\n",
       "      <td>454924</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>D13_is_null</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>16599</td>\n",
       "      <td>455833</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>D11_is_null</td>\n",
       "      <td>0.2168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>16599</td>\n",
       "      <td>455833</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>D15_uid_std</td>\n",
       "      <td>0.2168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>12965</td>\n",
       "      <td>292922</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>D7_is_null</td>\n",
       "      <td>0.2142</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>16599</td>\n",
       "      <td>455833</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>D7_normalized</td>\n",
       "      <td>0.2110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>4482</td>\n",
       "      <td>25462</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>D10_normalized</td>\n",
       "      <td>0.2092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>13311</td>\n",
       "      <td>392730</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>D1</td>\n",
       "      <td>0.2025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>16572</td>\n",
       "      <td>454924</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>D4</td>\n",
       "      <td>0.1891</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>11537</td>\n",
       "      <td>321121</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>D1_D4_ratio</td>\n",
       "      <td>0.1859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>6195</td>\n",
       "      <td>191680</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>D4_normalized</td>\n",
       "      <td>0.1664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>11537</td>\n",
       "      <td>321121</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>D10_D15_ratio</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>6508</td>\n",
       "      <td>244663</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>D11_normalized</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>4484</td>\n",
       "      <td>221975</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>D11</td>\n",
       "      <td>0.1554</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>4484</td>\n",
       "      <td>221975</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>D5_normalized</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>8569</td>\n",
       "      <td>210018</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>D14</td>\n",
       "      <td>0.1523</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>5712</td>\n",
       "      <td>44124</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>D2_is_null</td>\n",
       "      <td>0.1360</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>16599</td>\n",
       "      <td>455833</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>D6_normalized</td>\n",
       "      <td>0.1243</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>6031</td>\n",
       "      <td>52452</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>D13_normalized</td>\n",
       "      <td>0.1224</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>5317</td>\n",
       "      <td>43656</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>D9</td>\n",
       "      <td>0.1212</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>6247</td>\n",
       "      <td>55363</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>D3_normalized</td>\n",
       "      <td>0.1182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>7598</td>\n",
       "      <td>247182</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>D12</td>\n",
       "      <td>0.1167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>5993</td>\n",
       "      <td>46710</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>D14_normalized</td>\n",
       "      <td>0.0937</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>5712</td>\n",
       "      <td>44124</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>D6</td>\n",
       "      <td>0.0920</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>6031</td>\n",
       "      <td>52452</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>D12_normalized</td>\n",
       "      <td>0.0875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>5993</td>\n",
       "      <td>46710</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>D3_is_null</td>\n",
       "      <td>0.0845</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>16599</td>\n",
       "      <td>455833</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>D2_D3_ratio</td>\n",
       "      <td>0.0787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>3191</td>\n",
       "      <td>187582</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>D10_is_null</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>16599</td>\n",
       "      <td>455833</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>D10_D15_diff</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>12643</td>\n",
       "      <td>377036</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>D15_is_null</td>\n",
       "      <td>0.0572</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>16599</td>\n",
       "      <td>455833</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>D5_is_null</td>\n",
       "      <td>0.0555</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>16599</td>\n",
       "      <td>455833</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>D13</td>\n",
       "      <td>0.0441</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>5317</td>\n",
       "      <td>43656</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>D1_D4_diff</td>\n",
       "      <td>0.0412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>***</td>\n",
       "      <td>11520</td>\n",
       "      <td>320606</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>D1_D2_ratio</td>\n",
       "      <td>0.0347</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>***</td>\n",
       "      <td>5524</td>\n",
       "      <td>223091</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>D2_uid_std</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>***</td>\n",
       "      <td>10775</td>\n",
       "      <td>216130</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>D1_D2_diff</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.026553</td>\n",
       "      <td>*</td>\n",
       "      <td>6296</td>\n",
       "      <td>234873</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>D4_is_null</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.115199</td>\n",
       "      <td>ns</td>\n",
       "      <td>16599</td>\n",
       "      <td>455833</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>D1_is_null</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>ns</td>\n",
       "      <td>16599</td>\n",
       "      <td>455833</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Feature  Test_Stat   P_Value Significance  n_fraud  n_normal  \\\n",
       "0               D5     0.4414  0.000000          ***     8569    210018   \n",
       "1    D8_normalized     0.3785  0.000000          ***     6247     55363   \n",
       "2               D3     0.3684  0.000000          ***     7598    247182   \n",
       "3               D2     0.3318  0.000000          ***     6296    234873   \n",
       "4               D8     0.3102  0.000000          ***     6247     55363   \n",
       "5    D9_normalized     0.3087  0.000000          ***     6247     55363   \n",
       "6    D2_normalized     0.2960  0.000000          ***     6296    234873   \n",
       "7     D15_uid_mean     0.2958  0.000000          ***    15333    433855   \n",
       "8               D7     0.2895  0.000000          ***     4482     25462   \n",
       "9      D2_uid_mean     0.2738  0.000000          ***    13210    366385   \n",
       "10     D12_is_null     0.2586  0.000000          ***    16599    455833   \n",
       "11      D2_D3_diff     0.2553  0.000000          ***     5829    227970   \n",
       "12      D9_is_null     0.2549  0.000000          ***    16599    455833   \n",
       "13      D8_is_null     0.2549  0.000000          ***    16599    455833   \n",
       "14             D10     0.2518  0.000000          ***    13311    392730   \n",
       "15      D6_is_null     0.2483  0.000000          ***    16599    455833   \n",
       "16     D14_is_null     0.2473  0.000000          ***    16599    455833   \n",
       "17             D15     0.2414  0.000000          ***    12950    381717   \n",
       "18    D_null_count     0.2315  0.000000          ***    16599    455833   \n",
       "19  D15_normalized     0.2259  0.000000          ***    12950    381717   \n",
       "20   D1_normalized     0.2247  0.000000          ***    16572    454924   \n",
       "21     D13_is_null     0.2245  0.000000          ***    16599    455833   \n",
       "22     D11_is_null     0.2168  0.000000          ***    16599    455833   \n",
       "23     D15_uid_std     0.2168  0.000000          ***    12965    292922   \n",
       "24      D7_is_null     0.2142  0.000000          ***    16599    455833   \n",
       "25   D7_normalized     0.2110  0.000000          ***     4482     25462   \n",
       "26  D10_normalized     0.2092  0.000000          ***    13311    392730   \n",
       "27              D1     0.2025  0.000000          ***    16572    454924   \n",
       "28              D4     0.1891  0.000000          ***    11537    321121   \n",
       "29     D1_D4_ratio     0.1859  0.000000          ***     6195    191680   \n",
       "30   D4_normalized     0.1664  0.000000          ***    11537    321121   \n",
       "31   D10_D15_ratio     0.1630  0.000000          ***     6508    244663   \n",
       "32  D11_normalized     0.1587  0.000000          ***     4484    221975   \n",
       "33             D11     0.1554  0.000000          ***     4484    221975   \n",
       "34   D5_normalized     0.1550  0.000000          ***     8569    210018   \n",
       "35             D14     0.1523  0.000000          ***     5712     44124   \n",
       "36      D2_is_null     0.1360  0.000000          ***    16599    455833   \n",
       "37   D6_normalized     0.1243  0.000000          ***     6031     52452   \n",
       "38  D13_normalized     0.1224  0.000000          ***     5317     43656   \n",
       "39              D9     0.1212  0.000000          ***     6247     55363   \n",
       "40   D3_normalized     0.1182  0.000000          ***     7598    247182   \n",
       "41             D12     0.1167  0.000000          ***     5993     46710   \n",
       "42  D14_normalized     0.0937  0.000000          ***     5712     44124   \n",
       "43              D6     0.0920  0.000000          ***     6031     52452   \n",
       "44  D12_normalized     0.0875  0.000000          ***     5993     46710   \n",
       "45      D3_is_null     0.0845  0.000000          ***    16599    455833   \n",
       "46     D2_D3_ratio     0.0787  0.000000          ***     3191    187582   \n",
       "47     D10_is_null     0.0596  0.000000          ***    16599    455833   \n",
       "48    D10_D15_diff     0.0584  0.000000          ***    12643    377036   \n",
       "49     D15_is_null     0.0572  0.000000          ***    16599    455833   \n",
       "50      D5_is_null     0.0555  0.000000          ***    16599    455833   \n",
       "51             D13     0.0441  0.000000          ***     5317     43656   \n",
       "52      D1_D4_diff     0.0412  0.000000          ***    11520    320606   \n",
       "53     D1_D2_ratio     0.0347  0.000004          ***     5524    223091   \n",
       "54      D2_uid_std     0.0202  0.000458          ***    10775    216130   \n",
       "55      D1_D2_diff     0.0187  0.026553            *     6296    234873   \n",
       "56      D4_is_null     0.0094  0.115199           ns    16599    455833   \n",
       "57      D1_is_null     0.0004  1.000000           ns    16599    455833   \n",
       "\n",
       "    Unique_Ratio_Fraud  Unique_Ratio_Normal  \n",
       "0                0.036                0.003  \n",
       "1                0.999                0.994  \n",
       "2                0.031                0.002  \n",
       "3                0.079                0.003  \n",
       "4                0.180                0.093  \n",
       "5                0.999                0.977  \n",
       "6                0.999                0.997  \n",
       "7                0.165                0.017  \n",
       "8                0.047                0.022  \n",
       "9                0.051                0.006  \n",
       "10               0.000                0.000  \n",
       "11               0.082                0.003  \n",
       "12               0.000                0.000  \n",
       "13               0.000                0.000  \n",
       "14               0.043                0.002  \n",
       "15               0.000                0.000  \n",
       "16               0.000                0.000  \n",
       "17               0.046                0.002  \n",
       "18               0.001                0.000  \n",
       "19               0.999                0.992  \n",
       "20               0.999                0.987  \n",
       "21               0.000                0.000  \n",
       "22               0.000                0.000  \n",
       "23               0.186                0.041  \n",
       "24               0.000                0.000  \n",
       "25               1.000                0.999  \n",
       "26               0.999                0.991  \n",
       "27               0.033                0.001  \n",
       "28               0.049                0.002  \n",
       "29               0.234                0.059  \n",
       "30               0.999                0.992  \n",
       "31               0.161                0.044  \n",
       "32               0.998                0.994  \n",
       "33               0.110                0.003  \n",
       "34               0.998                0.993  \n",
       "35               0.058                0.017  \n",
       "36               0.000                0.000  \n",
       "37               1.000                0.998  \n",
       "38               1.000                0.998  \n",
       "39               0.004                0.000  \n",
       "40               0.999                0.991  \n",
       "41               0.055                0.013  \n",
       "42               1.000                0.998  \n",
       "43               0.056                0.015  \n",
       "44               1.000                0.998  \n",
       "45               0.000                0.000  \n",
       "46               0.368                0.040  \n",
       "47               0.000                0.000  \n",
       "48               0.042                0.003  \n",
       "49               0.000                0.000  \n",
       "50               0.000                0.000  \n",
       "51               0.022                0.012  \n",
       "52               0.062                0.004  \n",
       "53               0.046                0.013  \n",
       "54               0.019                0.006  \n",
       "55               0.010                0.002  \n",
       "56               0.000                0.000  \n",
       "57               0.000                0.000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feature_discrimination(\n",
    "    train_df,\n",
    "    columns=d_cols,  # Using properly tracked numerical features\n",
    "    target='isFraud',\n",
    "    test='ks',\n",
    "    min_samples=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf68efad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running KS test on 119 numerical features...\n",
      "KS Test Results - Top discriminating numerical features:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Feature",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Test_Stat",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "P_Value",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Significance",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "n_fraud",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "n_normal",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Unique_Ratio_Fraud",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Unique_Ratio_Normal",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "aba27653-aa24-4797-bd8b-1c5b861421fe",
       "rows": [
        [
         "0",
         "V258",
         "0.4613",
         "0.0",
         "***",
         "8174",
         "101761",
         "0.006",
         "0.0"
        ],
        [
         "1",
         "D5",
         "0.4414",
         "0.0",
         "***",
         "8569",
         "210018",
         "0.036",
         "0.003"
        ],
        [
         "2",
         "C13_C1_ratio",
         "0.4014",
         "0.0",
         "***",
         "16599",
         "455833",
         "0.071",
         "0.008"
        ],
        [
         "3",
         "V52",
         "0.3835",
         "0.0",
         "***",
         "11537",
         "321086",
         "0.001",
         "0.0"
        ],
        [
         "4",
         "D8_normalized",
         "0.3785",
         "0.0",
         "***",
         "6247",
         "55363",
         "0.999",
         "0.994"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Test_Stat</th>\n",
       "      <th>P_Value</th>\n",
       "      <th>Significance</th>\n",
       "      <th>n_fraud</th>\n",
       "      <th>n_normal</th>\n",
       "      <th>Unique_Ratio_Fraud</th>\n",
       "      <th>Unique_Ratio_Normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V258</td>\n",
       "      <td>0.4613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>***</td>\n",
       "      <td>8174</td>\n",
       "      <td>101761</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D5</td>\n",
       "      <td>0.4414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>***</td>\n",
       "      <td>8569</td>\n",
       "      <td>210018</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C13_C1_ratio</td>\n",
       "      <td>0.4014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>***</td>\n",
       "      <td>16599</td>\n",
       "      <td>455833</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V52</td>\n",
       "      <td>0.3835</td>\n",
       "      <td>0.0</td>\n",
       "      <td>***</td>\n",
       "      <td>11537</td>\n",
       "      <td>321086</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D8_normalized</td>\n",
       "      <td>0.3785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>***</td>\n",
       "      <td>6247</td>\n",
       "      <td>55363</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Feature  Test_Stat  P_Value Significance  n_fraud  n_normal  \\\n",
       "0           V258     0.4613      0.0          ***     8174    101761   \n",
       "1             D5     0.4414      0.0          ***     8569    210018   \n",
       "2   C13_C1_ratio     0.4014      0.0          ***    16599    455833   \n",
       "3            V52     0.3835      0.0          ***    11537    321086   \n",
       "4  D8_normalized     0.3785      0.0          ***     6247     55363   \n",
       "\n",
       "   Unique_Ratio_Fraud  Unique_Ratio_Normal  \n",
       "0               0.006                0.000  \n",
       "1               0.036                0.003  \n",
       "2               0.071                0.008  \n",
       "3               0.001                0.000  \n",
       "4               0.999                0.994  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Running KS test on {len(numerical_features)} numerical features...\")\n",
    "\n",
    "ks_results = test_feature_discrimination(\n",
    "    train_df,\n",
    "    columns=numerical_features,  # Using properly tracked numerical features\n",
    "    target='isFraud',\n",
    "    test='ks',\n",
    "    min_samples=30\n",
    ")\n",
    "\n",
    "# Display top results\n",
    "print(f\"KS Test Results - Top discriminating numerical features:\")\n",
    "display(ks_results.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a146c6d9",
   "metadata": {},
   "source": [
    "#### Remove High Correlated Features & Cap Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6a45784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Classification Summary (KS-based):\n",
      "  Strong (D >= 0.20): 51 features\n",
      "  Moderate (0.10 <= D < 0.20): 55 features\n",
      "  Weak (D < 0.10): 13 features\n",
      "\n",
      "Top 10 Strong Features: ['V258', 'D5', 'C13_C1_ratio', 'V52', 'D8_normalized', 'V201', 'V199', 'D3', 'V140', 'V94']\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Feature Classification by KS Statistic (Kolmogorov-Smirnov Two-Sample Test)\n",
    "# =============================================================================\n",
    "# \n",
    "# The KS statistic (D) measures the maximum vertical distance between the \n",
    "# cumulative distribution functions (CDFs) of two samples. In binary classification,\n",
    "# it quantifies how well a feature separates the two classes.\n",
    "#\n",
    "# Threshold Selection Rationale:\n",
    "# -----------------------------\n",
    "# - D >= 0.20: Strong discrimination (clearly separates fraud vs normal)\n",
    "# - 0.10 <= D < 0.20: Moderate discrimination (useful but weaker signal)\n",
    "# - D < 0.10: Weak discrimination (likely noise, may be dropped)\n",
    "#\n",
    "# Academic References:\n",
    "# 1. Siddiqi, N. (2006). \"Credit Risk Scorecards: Developing and Implementing \n",
    "#    Intelligent Credit Scoring\". Wiley. \n",
    "#    - Uses KS statistic as primary metric for feature discrimination in credit scoring\n",
    "#    - Suggests D > 0.20 as a practical threshold for \"good\" separation\n",
    "#\n",
    "# 2. Thomas, L.C., Edelman, D.B., & Crook, J.N. (2002). \"Credit Scoring and Its \n",
    "#    Applications\". SIAM.\n",
    "#    - Discusses KS test for comparing score distributions in fraud/credit models\n",
    "#\n",
    "# 3. Hand, D.J. & Henley, W.E. (1997). \"Statistical Classification Methods in \n",
    "#    Consumer Credit Scoring: A Review\". JRSS-A.\n",
    "#    - Reviews statistical methods including KS for feature evaluation\n",
    "#\n",
    "# Note: These thresholds are empirically derived from credit/fraud domain best practices.\n",
    "# The exact values may vary by dataset; validation via CV is always recommended.\n",
    "# =============================================================================\n",
    "\n",
    "# Define feature groups based on KS discrimination power\n",
    "strong_features = ks_results[ks_results['Test_Stat'] >= 0.20]['Feature'].tolist()\n",
    "moderate_features = ks_results[(ks_results['Test_Stat'] >= 0.05) & \n",
    "                               (ks_results['Test_Stat'] < 0.20)]['Feature'].tolist()\n",
    "weak_features = ks_results[ks_results['Test_Stat'] < 0.05]['Feature'].tolist()\n",
    "\n",
    "print(f\"Feature Classification Summary (KS-based):\")\n",
    "print(f\"  Strong (D >= 0.20): {len(strong_features)} features\")\n",
    "print(f\"  Moderate (0.10 <= D < 0.20): {len(moderate_features)} features\")\n",
    "print(f\"  Weak (D < 0.10): {len(weak_features)} features\")\n",
    "print(f\"\\nTop 10 Strong Features: {strong_features[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d9d1db",
   "metadata": {},
   "source": [
    "it is optional but we can remove weak features from the dataset. This is up to our total feature number.\n",
    "\n",
    "also I created a list named \"filtered_features\" and it seems that the best option is using this list for model training ! we don't have to remove..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0381453b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Optional: Remove Weak (and/or Moderate) Features from DataFrame\n",
    "# =============================================================================\n",
    "# Uncomment the appropriate section based on your needs\n",
    "\n",
    "# Option 1: Remove ONLY weak features (D < 0.10)\n",
    "# features_to_drop = weak_features\n",
    "# drop_reason = \"weak (KS < 0.10)\"\n",
    "\n",
    "# Option 2: Remove weak AND moderate features (D < 0.20)\n",
    "# features_to_drop = weak_features + moderate_features\n",
    "# drop_reason = \"weak + moderate (KS < 0.20)\"\n",
    "\n",
    "# Apply deletion (uncomment when ready)\n",
    "# train_df = train_df.drop(columns=[f for f in features_to_drop if f in train_df.columns], errors='ignore')\n",
    "# test_df = test_df.drop(columns=[f for f in features_to_drop if f in test_df.columns], errors='ignore')\n",
    "# print(f\"Dropped {len(features_to_drop)} {drop_reason} features\")\n",
    "# print(f\"New train shape: {train_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64f2a680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation removal: SKIPPED (keeping all 106 numerical features)\n",
      "Categorical features for model: 72\n",
      "\n",
      "============================================================\n",
      "FINAL FEATURE LIST: 178 features\n",
      "============================================================\n",
      "  Numerical features: 106\n",
      "  Categorical features: 72\n",
      "  Total: 178\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION FLAGS\n",
    "# =============================================================================\n",
    "APPLY_CORRELATION_REMOVAL = False  # Set to True to remove highly correlated features\n",
    "INCLUDE_WEAK_FEATURES = False       # Set to True to include weak KS features\n",
    "\n",
    "# =============================================================================\n",
    "# Build Final Feature List\n",
    "# =============================================================================\n",
    "\n",
    "# 1. Numerical features (based on KS discrimination)\n",
    "if INCLUDE_WEAK_FEATURES:\n",
    "    numerical_for_model = strong_features + moderate_features + weak_features\n",
    "else:\n",
    "    numerical_for_model = strong_features + moderate_features\n",
    "\n",
    "# 2. Apply correlation removal (optional)\n",
    "if APPLY_CORRELATION_REMOVAL:\n",
    "    filtered_numerical = remove_high_correlation(\n",
    "        train_df, \n",
    "        numerical_for_model,\n",
    "        ks_results,\n",
    "        threshold=0.95\n",
    "    )\n",
    "    print(f\"Correlation removal: {len(numerical_for_model)} -> {len(filtered_numerical)} numerical features\")\n",
    "else:\n",
    "    filtered_numerical = numerical_for_model\n",
    "    print(f\"Correlation removal: SKIPPED (keeping all {len(filtered_numerical)} numerical features)\")\n",
    "\n",
    "# 3. Categorical features (present in dataset after encoding)\n",
    "categorical_for_model = [col for col in categorical_features if col in train_df.columns]\n",
    "print(f\"Categorical features for model: {len(categorical_for_model)}\")\n",
    "\n",
    "# 4. COMBINE: Numerical + Categorical = Final Feature List\n",
    "filtered_features = filtered_numerical + categorical_for_model\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"FINAL FEATURE LIST: {len(filtered_features)} features\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"  Numerical features: {len(filtered_numerical)}\")\n",
    "print(f\"  Categorical features: {len(categorical_for_model)}\")\n",
    "print(f\"  Total: {len(filtered_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8502c03e",
   "metadata": {},
   "source": [
    "### Correlation Analysis Visualization\n",
    "\n",
    "Visualize the correlation structure among the filtered features to understand multicollinearity patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99f1b608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Correlation heatmap for top features (limit to 30 for readability)\n",
    "# top_features_for_viz = filtered_features[:30] if len(filtered_features) > 30 else filtered_features\n",
    "\n",
    "# if len(top_features_for_viz) > 0:\n",
    "#     corr_matrix = train_df[top_features_for_viz].corr()\n",
    "    \n",
    "#     plt.figure(figsize=(16, 14))\n",
    "#     mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "    \n",
    "#     sns.heatmap(\n",
    "#         corr_matrix, \n",
    "#         mask=mask,\n",
    "#         annot=False,  # Too many features for annotations\n",
    "#         cmap='RdBu_r', \n",
    "#         center=0,\n",
    "#         vmin=-1, \n",
    "#         vmax=1,\n",
    "#         square=True,\n",
    "#         linewidths=0.5,\n",
    "#         cbar_kws={'label': 'Correlation Coefficient'}\n",
    "#     )\n",
    "    \n",
    "#     plt.title('Feature Correlation Matrix (After High Correlation Removal)', fontsize=14, fontweight='bold')\n",
    "#     plt.xticks(rotation=45, ha='right', fontsize=8)\n",
    "#     plt.yticks(fontsize=8)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "    \n",
    "#     # Print highly correlated pairs that remain (if any)\n",
    "#     print(\"\\nRemaining correlations > 0.8:\")\n",
    "#     high_corr_pairs = []\n",
    "#     for i in range(len(corr_matrix.columns)):\n",
    "#         for j in range(i+1, len(corr_matrix.columns)):\n",
    "#             if abs(corr_matrix.iloc[i, j]) > 0.8:\n",
    "#                 high_corr_pairs.append((\n",
    "#                     corr_matrix.columns[i], \n",
    "#                     corr_matrix.columns[j], \n",
    "#                     round(corr_matrix.iloc[i, j], 3)\n",
    "#                 ))\n",
    "    \n",
    "#     if high_corr_pairs:\n",
    "#         for pair in high_corr_pairs[:10]:\n",
    "#             print(f\"  {pair[0]} <-> {pair[1]}: {pair[2]}\")\n",
    "#     else:\n",
    "#         print(\"  None found - good separation achieved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2059c147",
   "metadata": {},
   "source": [
    "### Outlier Analysis & Handling\n",
    "\n",
    "Extreme outliers can negatively impact model training. We use **Winsorization** (percentile capping) to handle outliers while preserving the overall distribution shape.\n",
    "\n",
    "**Method**: Cap values below the 1st percentile and above the 99th percentile.\n",
    "\n",
    "**Reference**: Hastie, T., Tibshirani, R., & Friedman, J. (2009). \"The Elements of Statistical Learning\". Springer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c065db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Identify features with significant outliers\n",
    "# def detect_outlier_features(df, features, iqr_multiplier=3.0):\n",
    "#     \"\"\"\n",
    "#     Detect features with extreme outliers using IQR method.\n",
    "    \n",
    "#     Args:\n",
    "#         df: DataFrame\n",
    "#         features: List of numerical features to check\n",
    "#         iqr_multiplier: Multiplier for IQR to define outlier bounds (default 3.0)\n",
    "    \n",
    "#     Returns:\n",
    "#         DataFrame with outlier statistics per feature\n",
    "#     \"\"\"\n",
    "#     outlier_stats = []\n",
    "    \n",
    "#     for col in features:\n",
    "#         if col not in df.columns:\n",
    "#             continue\n",
    "        \n",
    "#         data = df[col].dropna()\n",
    "#         if len(data) == 0:\n",
    "#             continue\n",
    "            \n",
    "#         Q1 = data.quantile(0.25)\n",
    "#         Q3 = data.quantile(0.75)\n",
    "#         IQR = Q3 - Q1\n",
    "        \n",
    "#         lower_bound = Q1 - iqr_multiplier * IQR\n",
    "#         upper_bound = Q3 + iqr_multiplier * IQR\n",
    "        \n",
    "#         outliers = data[(data < lower_bound) | (data > upper_bound)]\n",
    "#         outlier_pct = len(outliers) / len(data) * 100\n",
    "        \n",
    "#         if outlier_pct > 0.1:  # Only report if > 0.1% outliers\n",
    "#             outlier_stats.append({\n",
    "#                 'Feature': col,\n",
    "#                 'Outlier_Count': len(outliers),\n",
    "#                 'Outlier_Pct': round(outlier_pct, 2),\n",
    "#                 'Min': round(data.min(), 2),\n",
    "#                 'Max': round(data.max(), 2),\n",
    "#                 'Lower_Bound': round(lower_bound, 2),\n",
    "#                 'Upper_Bound': round(upper_bound, 2)\n",
    "#             })\n",
    "    \n",
    "#     return pd.DataFrame(outlier_stats).sort_values('Outlier_Pct', ascending=False)\n",
    "\n",
    "# # Detect outliers in filtered features\n",
    "# outlier_analysis = detect_outlier_features(train_df, filtered_features)\n",
    "# print(f\"Features with significant outliers (> 0.1%):\")\n",
    "# display(outlier_analysis.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c3bdb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply outlier capping to features with significant outliers\n",
    "# Using cap_outliers from numeric_functions.py\n",
    "\n",
    "# features_to_cap = outlier_analysis['Feature'].tolist() if len(outlier_analysis) > 0 else []\n",
    "\n",
    "# if features_to_cap:\n",
    "#     print(f\"Applying Winsorization to {len(features_to_cap)} features...\")\n",
    "    \n",
    "#     # IMPORTANT: Learn bounds from train, apply same bounds to test\n",
    "#     # Store the bounds for reproducibility\n",
    "#     cap_bounds = {}\n",
    "#     for col in features_to_cap:\n",
    "#         if col in train_df.columns:\n",
    "#             cap_bounds[col] = {\n",
    "#                 'lower': train_df[col].quantile(0.01),\n",
    "#                 'upper': train_df[col].quantile(0.99)\n",
    "#             }\n",
    "    \n",
    "#     # Apply to train\n",
    "#     train_df = cap_outliers(train_df, features_to_cap, lower_percentile=1, upper_percentile=99)\n",
    "    \n",
    "#     # Apply SAME bounds to test (using train's percentiles)\n",
    "#     for col in features_to_cap:\n",
    "#         if col in test_df.columns and col in cap_bounds:\n",
    "#             test_df[col] = test_df[col].clip(cap_bounds[col]['lower'], cap_bounds[col]['upper'])\n",
    "    \n",
    "#     print(\"Outlier capping completed!\")\n",
    "#     print(f\"\\nSample bounds applied:\")\n",
    "#     for col in list(cap_bounds.keys())[:5]:\n",
    "#         print(f\"  {col}: [{cap_bounds[col]['lower']:.2f}, {cap_bounds[col]['upper']:.2f}]\")\n",
    "# else:\n",
    "#     print(\"No features require outlier capping.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9f0f31",
   "metadata": {},
   "source": [
    "## Data Preparation Summary\n",
    "\n",
    "At this point, the following preprocessing steps have been completed:\n",
    "\n",
    "1. **Missing Value Handling**: Dropped features with >95% missing values\n",
    "2. **Categorical Engineering**: \n",
    "   - Rare category encoding for card3, card5\n",
    "   - Email domain consolidation\n",
    "   - Device info extraction\n",
    "   - Screen feature extraction\n",
    "   - Bivariate interaction features\n",
    "3. **Encoding**: Label encoding (low cardinality) + Frequency encoding (high cardinality)\n",
    "4. **Numerical Engineering**:\n",
    "   - V-column reduction via missing pattern grouping + KS selection\n",
    "   - Time features (TransactionDay, normalized D columns)\n",
    "   - UID-based aggregations (train-safe)\n",
    "   - Transaction amount features (log, decimal)\n",
    "   - C-velocity ratios\n",
    "5. **Feature Selection**: KS-test based classification (strong/moderate/weak)\n",
    "6. **Correlation Removal**: Removed highly correlated features (r > 0.95), keeping higher KS\n",
    "7. **Outlier Handling**: Winsorization (1st-99th percentile capping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1104ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FINAL DATASET SUMMARY\n",
      "============================================================\n",
      "\n",
      "Train shape: (472432, 195)\n",
      "Test shape: (118108, 195)\n",
      "\n",
      "Feature Type Tracking:\n",
      "  Total features: 195\n",
      "  Tracked categorical features: 72\n",
      "  True numerical features: 119\n",
      "  Exclude columns (ID, target, uid): 4\n",
      "\n",
      "Numerical Feature Selection (KS-based):\n",
      "  Filtered features for modeling: 178\n",
      "  Strong discrimination (KS >= 0.20): 51\n",
      "  Moderate discrimination (0.10 <= KS < 0.20): 55\n",
      "\n",
      "Target distribution (train):\n",
      "isFraud\n",
      "0    455833\n",
      "1     16599\n",
      "Name: count, dtype: int64\n",
      "Fraud rate: 3.51%\n"
     ]
    }
   ],
   "source": [
    "# Final dataset summary\n",
    "print(\"=\" * 60)\n",
    "print(\"FINAL DATASET SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTrain shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "\n",
    "print(f\"\\nFeature Type Tracking:\")\n",
    "print(f\"  Total features: {train_df.shape[1]}\")\n",
    "print(f\"  Tracked categorical features: {len(categorical_features)}\")\n",
    "print(f\"  True numerical features: {len(numerical_features)}\")\n",
    "print(f\"  Exclude columns (ID, target, uid): {len(exclude_cols)}\")\n",
    "\n",
    "print(f\"\\nNumerical Feature Selection (KS-based):\")\n",
    "print(f\"  Filtered features for modeling: {len(filtered_features)}\")\n",
    "print(f\"  Strong discrimination (KS >= 0.20): {len(strong_features)}\")\n",
    "print(f\"  Moderate discrimination (0.10 <= KS < 0.20): {len(moderate_features)}\")\n",
    "\n",
    "print(f\"\\nTarget distribution (train):\")\n",
    "print(train_df['isFraud'].value_counts())\n",
    "print(f\"Fraud rate: {train_df['isFraud'].mean()*100:.2f}%\")\n",
    "\n",
    "# print(\"\\n\" + \"=\" * 60)\n",
    "# print(\"Data preparation complete! Ready for model training.\")\n",
    "# print(\"=\" * 60)\n",
    "# print(\"\\nNote: Categorical features were tracked throughout the notebook\")\n",
    "# print(\"and properly excluded from numerical feature analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74d6bc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data saved successfully!\n",
      "   - train_preprocessed.parquet: (472432, 195)\n",
      "   - test_preprocessed.parquet: (118108, 195)\n",
      "   - feature_lists.pkl: 178 filtered features\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Save Preprocessed Data for Modeling\n",
    "# =============================================================================\n",
    "import pickle\n",
    "\n",
    "# Save DataFrames as parquet (efficient for large data)\n",
    "train_df.to_parquet(DATA / \"train_preprocessed.parquet\", index=False)\n",
    "test_df.to_parquet(DATA / \"test_preprocessed.parquet\", index=False)\n",
    "\n",
    "# Save feature lists\n",
    "feature_lists = {\n",
    "    'filtered_features': filtered_features,\n",
    "    'categorical_features': categorical_features,\n",
    "    'strong_features': strong_features,\n",
    "    'moderate_features': moderate_features\n",
    "}\n",
    "\n",
    "with open(DATA / \"feature_lists.pkl\", 'wb') as f:\n",
    "    pickle.dump(feature_lists, f)\n",
    "\n",
    "print(\"✅ Data saved successfully!\")\n",
    "print(f\"   - train_preprocessed.parquet: {train_df.shape}\")\n",
    "print(f\"   - test_preprocessed.parquet: {test_df.shape}\")\n",
    "print(f\"   - feature_lists.pkl: {len(filtered_features)} filtered features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100e2052",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
