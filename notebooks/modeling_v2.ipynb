{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ab58cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import time\n",
    "import pickle\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, average_precision_score, precision_score, recall_score, f1_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import sys\n",
    "ROOT = Path.cwd().parent\n",
    "sys.path.append(str(ROOT / 'functions'))\n",
    "DATA = ROOT / 'data'\n",
    "\n",
    "print('Libraries loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f9756a",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "\n",
    "**Important**: We use `train_merged.csv` and perform an 80/20 temporal split (same as EDA.ipynb).\n",
    "The `test_merged.csv` is the Kaggle competition test set without labels - not used for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5f8cb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data loaded and split (80/20 temporal):\n",
      "  Train: (472432, 434)\n",
      "  Test: (118108, 434)\n",
      "Preprocessed train: (472432, 195)\n"
     ]
    }
   ],
   "source": [
    "# Load raw merged data (train only - test_merged.csv has no labels!)\n",
    "df_raw = pd.read_csv(DATA / 'train_merged.csv')\n",
    "\n",
    "# Temporal split (same as EDA.ipynb - 80/20)\n",
    "df_raw = df_raw.sort_values('TransactionDT').reset_index(drop=True)\n",
    "split_idx = int(len(df_raw) * 0.8)\n",
    "\n",
    "train_raw = df_raw.iloc[:split_idx].copy()\n",
    "test_raw = df_raw.iloc[split_idx:].copy()\n",
    "\n",
    "# Also load preprocessed data for Scenario 5 (feature importance)\n",
    "train_preprocessed = pd.read_parquet(DATA / 'train_preprocessed.parquet')\n",
    "test_preprocessed = pd.read_parquet(DATA / 'test_preprocessed.parquet')\n",
    "\n",
    "with open(DATA / 'feature_lists.pkl', 'rb') as f:\n",
    "    feature_lists = pickle.load(f)\n",
    "\n",
    "print(f'Raw data loaded and split (80/20 temporal):')\n",
    "print(f'  Train: {train_raw.shape}')\n",
    "print(f'  Test: {test_raw.shape}')\n",
    "print(f'Preprocessed train: {train_preprocessed.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2b6567d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 472432, Test samples: 118108\n",
      "Train fraud rate: 3.51%\n",
      "Test fraud rate: 3.44%\n",
      "Class imbalance ratio: 27.46\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "N_FOLDS = 3\n",
    "CV_RANDOM_STATE = 42\n",
    "BLEND_VAL_SIZE = 0.2\n",
    "\n",
    "# Target variable (from temporal split)\n",
    "y_train_full = train_raw['isFraud'].copy()\n",
    "y_test = test_raw['isFraud'].copy()\n",
    "\n",
    "# Class imbalance ratio\n",
    "scale_pos_weight = (y_train_full == 0).sum() / (y_train_full == 1).sum()\n",
    "\n",
    "print(f'Train samples: {len(y_train_full)}, Test samples: {len(y_test)}')\n",
    "print(f'Train fraud rate: {y_train_full.mean()*100:.2f}%')\n",
    "print(f'Test fraud rate: {y_test.mean()*100:.2f}%')\n",
    "print(f'Class imbalance ratio: {scale_pos_weight:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4cc234",
   "metadata": {},
   "source": [
    "## 2. Define Column Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b78415a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C columns (count): 14\n",
      "D columns (time delta): 15\n",
      "V columns (Vesta): 339\n",
      "M columns (match): 9\n",
      "ID columns: 38\n",
      "Transaction columns: 15\n"
     ]
    }
   ],
   "source": [
    "# Identify column groups from raw data\n",
    "all_cols = [c for c in train_raw.columns if c not in ['TransactionID', 'isFraud']]\n",
    "\n",
    "# C columns (count features - historical)\n",
    "c_cols = [c for c in all_cols if c.startswith('C') and c[1:].isdigit()]\n",
    "\n",
    "# D columns (time delta features - historical)\n",
    "d_cols = [c for c in all_cols if c.startswith('D') and c[1:].isdigit()]\n",
    "\n",
    "# V columns (Vesta features - historical comparisons)\n",
    "v_cols = [c for c in all_cols if c.startswith('V') and c[1:].isdigit()]\n",
    "\n",
    "# M columns (match features)\n",
    "m_cols = [c for c in all_cols if c.startswith('M') and len(c) <= 3]\n",
    "\n",
    "# ID columns\n",
    "id_cols = [c for c in all_cols if c.startswith('id_')]\n",
    "\n",
    "# Transaction columns (non-historical)\n",
    "transaction_cols = ['TransactionDT', 'TransactionAmt', 'ProductCD', \n",
    "                    'card1', 'card2', 'card3', 'card4', 'card5', 'card6',\n",
    "                    'addr1', 'addr2', 'dist1', 'dist2', \n",
    "                    'P_emaildomain', 'R_emaildomain']\n",
    "\n",
    "# Device columns\n",
    "device_cols = ['DeviceType', 'DeviceInfo']\n",
    "\n",
    "# Categorical columns in raw data\n",
    "raw_categorical = ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain',\n",
    "                   'DeviceType', 'DeviceInfo'] + m_cols + [c for c in id_cols if train_raw[c].dtype == 'object']\n",
    "\n",
    "print(f'C columns (count): {len(c_cols)}')\n",
    "print(f'D columns (time delta): {len(d_cols)}')\n",
    "print(f'V columns (Vesta): {len(v_cols)}')\n",
    "print(f'M columns (match): {len(m_cols)}')\n",
    "print(f'ID columns: {len(id_cols)}')\n",
    "print(f'Transaction columns: {len(transaction_cols)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178a0f5d",
   "metadata": {},
   "source": [
    "## 3. Model Factory Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09562a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model factories defined\n"
     ]
    }
   ],
   "source": [
    "def create_random_forest(use_imputer=False):\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=200, max_depth=15, min_samples_split=10,\n",
    "        min_samples_leaf=5, class_weight='balanced', random_state=42, n_jobs=-1\n",
    "    )\n",
    "    if use_imputer:\n",
    "        return Pipeline([('imputer', SimpleImputer(strategy='median')), ('classifier', rf)])\n",
    "    return rf\n",
    "\n",
    "def create_xgboost(spw):\n",
    "    return XGBClassifier(\n",
    "        n_estimators=300, max_depth=6, learning_rate=0.05,\n",
    "        subsample=0.8, colsample_bytree=0.8, scale_pos_weight=spw,\n",
    "        eval_metric='auc', random_state=42, n_jobs=-1\n",
    "    )\n",
    "\n",
    "def create_lightgbm():\n",
    "    return LGBMClassifier(\n",
    "        n_estimators=300, max_depth=8, learning_rate=0.05,\n",
    "        num_leaves=31, subsample=0.8, colsample_bytree=0.8,\n",
    "        is_unbalance=True, random_state=42, n_jobs=-1, verbose=-1\n",
    "    )\n",
    "\n",
    "def create_catboost(cat_features=None):\n",
    "    return CatBoostClassifier(\n",
    "        iterations=300, depth=6, learning_rate=0.05,\n",
    "        auto_class_weights='Balanced', eval_metric='AUC',\n",
    "        random_seed=42, verbose=0, cat_features=cat_features\n",
    "    )\n",
    "\n",
    "def get_base_models(spw, use_imputer=False, cat_features=None):\n",
    "    return {\n",
    "        'RandomForest': create_random_forest(use_imputer),\n",
    "        'XGBoost': create_xgboost(spw),\n",
    "        'LightGBM': create_lightgbm(),\n",
    "        'CatBoost': create_catboost(cat_features)\n",
    "    }\n",
    "\n",
    "print('Model factories defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1020e5",
   "metadata": {},
   "source": [
    "## 4. Ensemble Methods\n",
    "\n",
    "Four ensemble approaches:\n",
    "1. **Stacking_Weighted**: Simple weighted average based on CV-AUC\n",
    "2. **Stacking_MLP**: Neural network meta-learner trained on OOF predictions\n",
    "3. **Stacking_Blend**: Holdout-based blending (faster, no OOF needed)\n",
    "4. **Rank_Average**: Rank-based averaging (calibration-free, robust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbca0cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble methods defined\n"
     ]
    }
   ],
   "source": [
    "def ensemble_weighted_average(test_preds, cv_scores):\n",
    "    \"\"\"Weighted average based on CV-AUC scores.\"\"\"\n",
    "    model_names = list(test_preds.keys())\n",
    "    total = sum(cv_scores[m] for m in model_names)\n",
    "    weights = np.array([cv_scores[m] / total for m in model_names])\n",
    "    test_matrix = np.column_stack([test_preds[m] for m in model_names])\n",
    "    return np.dot(test_matrix, weights)\n",
    "\n",
    "\n",
    "def ensemble_mlp(oof_preds, y_train, test_preds, model_names):\n",
    "    \"\"\"MLP neural network meta-learner trained on OOF predictions.\"\"\"\n",
    "    oof_matrix = np.column_stack([oof_preds[m] for m in model_names])\n",
    "    test_matrix = np.column_stack([test_preds[m] for m in model_names])\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    oof_scaled = scaler.fit_transform(oof_matrix)\n",
    "    test_scaled = scaler.transform(test_matrix)\n",
    "    \n",
    "    mlp = MLPClassifier(\n",
    "        hidden_layer_sizes=(16, 8),\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        alpha=0.01,\n",
    "        max_iter=500,\n",
    "        random_state=42,\n",
    "        early_stopping=True,\n",
    "        validation_fraction=0.1\n",
    "    )\n",
    "    mlp.fit(oof_scaled, y_train)\n",
    "    return mlp.predict_proba(test_scaled)[:, 1]\n",
    "\n",
    "\n",
    "def ensemble_blend(X_train, y_train, X_test, base_models, blend_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Blending: Split train into train/blend, train base models on train,\n",
    "    predict on blend set to train meta-learner, then predict on test.\n",
    "    Faster than OOF stacking.\n",
    "    \"\"\"\n",
    "    X_tr, X_blend, y_tr, y_blend = train_test_split(\n",
    "        X_train, y_train, test_size=blend_size, stratify=y_train, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    blend_preds = {}\n",
    "    test_preds = {}\n",
    "    \n",
    "    for name, model in base_models.items():\n",
    "        m = clone(model)\n",
    "        m.fit(X_tr, y_tr)\n",
    "        blend_preds[name] = m.predict_proba(X_blend)[:, 1]\n",
    "        test_preds[name] = m.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    model_names = list(base_models.keys())\n",
    "    blend_matrix = np.column_stack([blend_preds[m] for m in model_names])\n",
    "    test_matrix = np.column_stack([test_preds[m] for m in model_names])\n",
    "    \n",
    "    meta = LogisticRegression(C=1.0, class_weight='balanced', max_iter=1000, random_state=42)\n",
    "    meta.fit(blend_matrix, y_blend)\n",
    "    \n",
    "    return meta.predict_proba(test_matrix)[:, 1]\n",
    "\n",
    "\n",
    "def ensemble_rank_average(test_preds):\n",
    "    \"\"\"Rank-based averaging. Robust to different probability calibrations.\"\"\"\n",
    "    model_names = list(test_preds.keys())\n",
    "    n_samples = len(test_preds[model_names[0]])\n",
    "    \n",
    "    rank_sum = np.zeros(n_samples)\n",
    "    for name in model_names:\n",
    "        ranks = rankdata(test_preds[name])\n",
    "        rank_sum += ranks\n",
    "    \n",
    "    # Normalize to [0, 1]\n",
    "    return rank_sum / (len(model_names) * n_samples)\n",
    "\n",
    "\n",
    "print('Ensemble methods defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184632a7",
   "metadata": {},
   "source": [
    "## 5. Data Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64e8d807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing functions defined\n"
     ]
    }
   ],
   "source": [
    "def preprocess_for_models(X_train, X_test, categorical_cols=None):\n",
    "    \"\"\"\n",
    "    Minimal preprocessing for raw data:\n",
    "    - Fill NaN with -999 for numerical\n",
    "    - Label encode categoricals\n",
    "    - Handle infinity\n",
    "    \"\"\"\n",
    "    X_train = X_train.copy()\n",
    "    X_test = X_test.copy()\n",
    "    \n",
    "    # Replace infinity\n",
    "    X_train = X_train.replace([np.inf, -np.inf], np.nan)\n",
    "    X_test = X_test.replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    # Identify categorical columns if not provided\n",
    "    if categorical_cols is None:\n",
    "        categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    # Label encode categoricals\n",
    "    cat_indices = []\n",
    "    for i, col in enumerate(X_train.columns):\n",
    "        if col in categorical_cols:\n",
    "            cat_indices.append(i)\n",
    "            le = LabelEncoder()\n",
    "            combined = pd.concat([X_train[col].astype(str), X_test[col].astype(str)])\n",
    "            le.fit(combined)\n",
    "            X_train[col] = le.transform(X_train[col].astype(str))\n",
    "            X_test[col] = le.transform(X_test[col].astype(str))\n",
    "    \n",
    "    # Fill NaN with sentinel\n",
    "    X_train = X_train.fillna(-999)\n",
    "    X_test = X_test.fillna(-999)\n",
    "    \n",
    "    return X_train, X_test, cat_indices\n",
    "\n",
    "\n",
    "def evaluate_on_test(y_true, y_prob):\n",
    "    \"\"\"Calculate test metrics with Youden-optimal threshold.\"\"\"\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "    ap = average_precision_score(y_true, y_prob)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_prob)\n",
    "    j_scores = tpr - fpr\n",
    "    opt_idx = np.argmax(j_scores)\n",
    "    opt_thresh = thresholds[opt_idx]\n",
    "    \n",
    "    y_pred = (y_prob >= opt_thresh).astype(int)\n",
    "    \n",
    "    return {\n",
    "        'Test_AUC': auc,\n",
    "        'Test_AP': ap,\n",
    "        'Optimal_Threshold': opt_thresh,\n",
    "        'Precision_opt': precision_score(y_true, y_pred, zero_division=0),\n",
    "        'Recall_opt': recall_score(y_true, y_pred, zero_division=0),\n",
    "        'F1_opt': f1_score(y_true, y_pred, zero_division=0)\n",
    "    }\n",
    "\n",
    "\n",
    "print('Preprocessing functions defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c532a3",
   "metadata": {},
   "source": [
    "## 6. Scenario Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76405a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario runner defined\n"
     ]
    }
   ],
   "source": [
    "def run_scenario(scenario_id, name, X_train, X_test, y_train, y_test, \n",
    "                 scale_pos_weight, cat_indices=None, n_folds=3):\n",
    "    \"\"\"\n",
    "    Run complete scenario with base models and ensemble methods.\n",
    "    \"\"\"\n",
    "    print(f'\\n{\"=\"*70}')\n",
    "    print(f'SCENARIO {scenario_id}: {name}')\n",
    "    print(f'Features: {X_train.shape[1]}, Samples: {len(X_train)}')\n",
    "    print('='*70)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=CV_RANDOM_STATE)\n",
    "    base_models = get_base_models(scale_pos_weight, use_imputer=False, cat_features=cat_indices)\n",
    "    \n",
    "    results = []\n",
    "    oof_predictions = {}\n",
    "    test_predictions = {}\n",
    "    cv_scores = {}\n",
    "    \n",
    "    # Train base models with CV\n",
    "    for model_name, model in base_models.items():\n",
    "        start = time.time()\n",
    "        oof_probs = np.zeros(len(X_train))\n",
    "        fold_scores = []\n",
    "        \n",
    "        for fold, (tr_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "            X_tr, X_val = X_train.iloc[tr_idx], X_train.iloc[val_idx]\n",
    "            y_tr, y_val = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n",
    "            \n",
    "            m = clone(model)\n",
    "            m.fit(X_tr, y_tr)\n",
    "            \n",
    "            probs = m.predict_proba(X_val)[:, 1]\n",
    "            oof_probs[val_idx] = probs\n",
    "            fold_scores.append(roc_auc_score(y_val, probs))\n",
    "        \n",
    "        cv_mean, cv_std = np.mean(fold_scores), np.std(fold_scores)\n",
    "        oof_predictions[model_name] = oof_probs\n",
    "        cv_scores[model_name] = cv_mean\n",
    "        \n",
    "        # Final model on full train\n",
    "        final_model = clone(model)\n",
    "        final_model.fit(X_train, y_train)\n",
    "        test_probs = final_model.predict_proba(X_test)[:, 1]\n",
    "        test_predictions[model_name] = test_probs\n",
    "        \n",
    "        metrics = evaluate_on_test(y_test, test_probs)\n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "        results.append({\n",
    "            'Scenario': scenario_id,\n",
    "            'Approach': model_name,\n",
    "            'CV_AUC_mean': cv_mean,\n",
    "            'CV_AUC_std': cv_std,\n",
    "            **metrics\n",
    "        })\n",
    "        print(f'  {model_name}: CV={cv_mean:.4f}+/-{cv_std:.4f}, Test={metrics[\"Test_AUC\"]:.4f} ({elapsed:.1f}s)')\n",
    "    \n",
    "    # Ensemble 1: Weighted Average\n",
    "    weighted_probs = ensemble_weighted_average(test_predictions, cv_scores)\n",
    "    metrics = evaluate_on_test(y_test, weighted_probs)\n",
    "    results.append({'Scenario': scenario_id, 'Approach': 'Stacking_Weighted',\n",
    "                    'CV_AUC_mean': np.nan, 'CV_AUC_std': np.nan, **metrics})\n",
    "    print(f'  Stacking_Weighted: Test={metrics[\"Test_AUC\"]:.4f}')\n",
    "    \n",
    "    # Ensemble 2: MLP Meta-learner\n",
    "    model_names = list(base_models.keys())\n",
    "    mlp_probs = ensemble_mlp(oof_predictions, y_train, test_predictions, model_names)\n",
    "    metrics = evaluate_on_test(y_test, mlp_probs)\n",
    "    results.append({'Scenario': scenario_id, 'Approach': 'Stacking_MLP',\n",
    "                    'CV_AUC_mean': np.nan, 'CV_AUC_std': np.nan, **metrics})\n",
    "    print(f'  Stacking_MLP: Test={metrics[\"Test_AUC\"]:.4f}')\n",
    "    \n",
    "    # Ensemble 3: Blending\n",
    "    blend_probs = ensemble_blend(X_train, y_train, X_test, base_models, \n",
    "                                  blend_size=BLEND_VAL_SIZE, random_state=CV_RANDOM_STATE)\n",
    "    metrics = evaluate_on_test(y_test, blend_probs)\n",
    "    results.append({'Scenario': scenario_id, 'Approach': 'Stacking_Blend',\n",
    "                    'CV_AUC_mean': np.nan, 'CV_AUC_std': np.nan, **metrics})\n",
    "    print(f'  Stacking_Blend: Test={metrics[\"Test_AUC\"]:.4f}')\n",
    "    \n",
    "    # Ensemble 4: Rank Average\n",
    "    rank_probs = ensemble_rank_average(test_predictions)\n",
    "    metrics = evaluate_on_test(y_test, rank_probs)\n",
    "    results.append({'Scenario': scenario_id, 'Approach': 'Rank_Average',\n",
    "                    'CV_AUC_mean': np.nan, 'CV_AUC_std': np.nan, **metrics})\n",
    "    print(f'  Rank_Average: Test={metrics[\"Test_AUC\"]:.4f}')\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "print('Scenario runner defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48e1b8e",
   "metadata": {},
   "source": [
    "## 7. Define and Execute Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ea17da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store scenario metadata\n",
    "SCENARIOS = {}\n",
    "all_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbba6aba",
   "metadata": {},
   "source": [
    "### Scenario 1: Raw Data Baseline\n",
    "\n",
    "Use train_merged and test_merged with minimal preprocessing. This establishes the \"before\" state to demonstrate the value of feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d567370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SCENARIO 1: Raw Data Baseline\n",
      "Features: 432, Samples: 472432\n",
      "======================================================================\n",
      "  RandomForest: CV=0.9116+/-0.0016, Test=0.8723 (266.1s)\n",
      "  XGBoost: CV=0.9380+/-0.0009, Test=0.9078 (760.7s)\n",
      "  LightGBM: CV=0.9371+/-0.0007, Test=0.9085 (59.3s)\n",
      "  CatBoost: CV=0.9170+/-0.0007, Test=0.8943 (824.7s)\n",
      "  Stacking_Weighted: Test=0.9051\n",
      "  Stacking_MLP: Test=0.9069\n",
      "  Stacking_Blend: Test=0.8964\n",
      "  Rank_Average: Test=0.9021\n"
     ]
    }
   ],
   "source": [
    "# Scenario 1: Raw Data Baseline\n",
    "feature_cols = [c for c in train_raw.columns if c not in ['TransactionID', 'isFraud']]\n",
    "\n",
    "X_train_s1 = train_raw[feature_cols].copy()\n",
    "X_test_s1 = test_raw[feature_cols].copy()\n",
    "y_train_s1 = y_train_full.copy()\n",
    "\n",
    "X_train_s1, X_test_s1, cat_idx_s1 = preprocess_for_models(X_train_s1, X_test_s1)\n",
    "\n",
    "SCENARIOS[1] = {\n",
    "    'name': 'Raw Data Baseline',\n",
    "    'description': 'No feature engineering, minimal preprocessing',\n",
    "    'n_features': X_train_s1.shape[1]\n",
    "}\n",
    "\n",
    "results_s1 = run_scenario(1, SCENARIOS[1]['name'], X_train_s1, X_test_s1, \n",
    "                          y_train_s1, y_test, scale_pos_weight, cat_idx_s1)\n",
    "all_results.append(results_s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d174aeb2",
   "metadata": {},
   "source": [
    "### Scenario 2: High Cardinality Categorical Focus\n",
    "\n",
    "Focus on raw categorical columns without frequency encoding. Test which model handles high-cardinality best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a8b1b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SCENARIO 2: High Cardinality Categorical\n",
      "Features: 23, Samples: 472432\n",
      "======================================================================\n",
      "  RandomForest: CV=0.9000+/-0.0012, Test=0.8413 (69.0s)\n",
      "  XGBoost: CV=0.8939+/-0.0015, Test=0.8413 (101.9s)\n",
      "  LightGBM: CV=0.8888+/-0.0006, Test=0.8441 (11.4s)\n",
      "  CatBoost: CV=0.8687+/-0.0012, Test=0.8211 (465.0s)\n",
      "  Stacking_Weighted: Test=0.8449\n",
      "  Stacking_MLP: Test=0.8467\n",
      "  Stacking_Blend: Test=0.8428\n",
      "  Rank_Average: Test=0.8442\n"
     ]
    }
   ],
   "source": [
    "# Scenario 2: High Cardinality Categorical Focus\n",
    "# Include card columns, email domains, device info, M columns\n",
    "cat_focus_cols = ['TransactionAmt', 'ProductCD', \n",
    "                  'card1', 'card2', 'card3', 'card4', 'card5', 'card6',\n",
    "                  'addr1', 'addr2', \n",
    "                  'P_emaildomain', 'R_emaildomain',\n",
    "                  'DeviceType', 'DeviceInfo'] + m_cols\n",
    "\n",
    "cat_focus_cols = [c for c in cat_focus_cols if c in train_raw.columns]\n",
    "\n",
    "X_train_s2 = train_raw[cat_focus_cols].copy()\n",
    "X_test_s2 = test_raw[cat_focus_cols].copy()\n",
    "y_train_s2 = y_train_full.copy()\n",
    "\n",
    "X_train_s2, X_test_s2, cat_idx_s2 = preprocess_for_models(X_train_s2, X_test_s2)\n",
    "\n",
    "SCENARIOS[2] = {\n",
    "    'name': 'High Cardinality Categorical',\n",
    "    'description': 'Raw categoricals with minimal encoding',\n",
    "    'n_features': X_train_s2.shape[1]\n",
    "}\n",
    "\n",
    "results_s2 = run_scenario(2, SCENARIOS[2]['name'], X_train_s2, X_test_s2,\n",
    "                          y_train_s2, y_test, scale_pos_weight, cat_idx_s2)\n",
    "all_results.append(results_s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee38a045",
   "metadata": {},
   "source": [
    "### Scenario 3: Numerical Features Only\n",
    "\n",
    "Remove all categorical features. Keep only numerical signals to test pure numerical optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c44b2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SCENARIO 3: Numerical Only\n",
      "Features: 395, Samples: 472432\n",
      "======================================================================\n",
      "  RandomForest: CV=0.9008+/-0.0012, Test=0.8630 (249.5s)\n",
      "  XGBoost: CV=0.9208+/-0.0013, Test=0.8865 (707.0s)\n",
      "  LightGBM: CV=0.9200+/-0.0014, Test=0.8849 (61.0s)\n",
      "  CatBoost: CV=0.9014+/-0.0016, Test=0.8818 (144.2s)\n",
      "  Stacking_Weighted: Test=0.8865\n",
      "  Stacking_MLP: Test=0.8745\n",
      "  Stacking_Blend: Test=0.8672\n",
      "  Rank_Average: Test=0.8838\n"
     ]
    }
   ],
   "source": [
    "# Scenario 3: Numerical Only\n",
    "numerical_cols = ['TransactionDT', 'TransactionAmt', 'dist1', 'dist2']\n",
    "numerical_cols += c_cols + d_cols + v_cols\n",
    "numerical_cols += [c for c in id_cols if train_raw[c].dtype in ['int64', 'float64']]\n",
    "numerical_cols = [c for c in numerical_cols if c in train_raw.columns]\n",
    "\n",
    "X_train_s3 = train_raw[numerical_cols].copy()\n",
    "X_test_s3 = test_raw[numerical_cols].copy()\n",
    "y_train_s3 = y_train_full.copy()\n",
    "\n",
    "# No categoricals here\n",
    "X_train_s3 = X_train_s3.replace([np.inf, -np.inf], np.nan).fillna(-999)\n",
    "X_test_s3 = X_test_s3.replace([np.inf, -np.inf], np.nan).fillna(-999)\n",
    "\n",
    "SCENARIOS[3] = {\n",
    "    'name': 'Numerical Only',\n",
    "    'description': 'No categorical features, pure numerical',\n",
    "    'n_features': X_train_s3.shape[1]\n",
    "}\n",
    "\n",
    "results_s3 = run_scenario(3, SCENARIOS[3]['name'], X_train_s3, X_test_s3,\n",
    "                          y_train_s3, y_test, scale_pos_weight, cat_indices=None)\n",
    "all_results.append(results_s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d14546d",
   "metadata": {},
   "source": [
    "### Scenario 4: The Amnesiac System\n",
    "\n",
    "**Story**: What if the system can't access historical data? During high-load events, we need to make decisions using only current transaction data.\n",
    "\n",
    "Remove all \"memory\" columns:\n",
    "- C columns (count history)\n",
    "- D columns (time deltas)\n",
    "- V columns (Vesta historical comparisons)\n",
    "\n",
    "Keep only: Transaction basics, Card info, Address, Email, Device, Identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c74b37a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historical columns removed: C=14, D=15, V=339\n",
      "Remaining features: 64\n",
      "\n",
      "======================================================================\n",
      "SCENARIO 4: Amnesiac System\n",
      "Features: 64, Samples: 472432\n",
      "======================================================================\n",
      "  RandomForest: CV=0.9036+/-0.0016, Test=0.8356 (100.7s)\n",
      "  XGBoost: CV=0.9058+/-0.0005, Test=0.8460 (187.1s)\n",
      "  LightGBM: CV=0.9026+/-0.0008, Test=0.8519 (15.4s)\n",
      "  CatBoost: CV=0.8788+/-0.0020, Test=0.8291 (739.2s)\n",
      "  Stacking_Weighted: Test=0.8494\n",
      "  Stacking_MLP: Test=0.8529\n",
      "  Stacking_Blend: Test=0.8343\n",
      "  Rank_Average: Test=0.8482\n"
     ]
    }
   ],
   "source": [
    "# Scenario 4: Amnesiac System - No historical data (C, D, V columns)\n",
    "history_cols = set(c_cols + d_cols + v_cols)\n",
    "amnesiac_cols = [c for c in train_raw.columns \n",
    "                 if c not in ['TransactionID', 'isFraud'] and c not in history_cols]\n",
    "\n",
    "X_train_s4 = train_raw[amnesiac_cols].copy()\n",
    "X_test_s4 = test_raw[amnesiac_cols].copy()\n",
    "y_train_s4 = y_train_full.copy()\n",
    "\n",
    "X_train_s4, X_test_s4, cat_idx_s4 = preprocess_for_models(X_train_s4, X_test_s4)\n",
    "\n",
    "SCENARIOS[4] = {\n",
    "    'name': 'Amnesiac System',\n",
    "    'description': 'No C/D/V columns - real-time only data',\n",
    "    'n_features': X_train_s4.shape[1]\n",
    "}\n",
    "\n",
    "print(f'Historical columns removed: C={len(c_cols)}, D={len(d_cols)}, V={len(v_cols)}')\n",
    "print(f'Remaining features: {X_train_s4.shape[1]}')\n",
    "\n",
    "results_s4 = run_scenario(4, SCENARIOS[4]['name'], X_train_s4, X_test_s4,\n",
    "                          y_train_s4, y_test, scale_pos_weight, cat_idx_s4)\n",
    "all_results.append(results_s4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a938285",
   "metadata": {},
   "source": [
    "### Scenario 5: Top 40 Features\n",
    "\n",
    "Select top 40 features based on importance from preprocessed data. Test which model generalizes best with limited but high-quality features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fbef483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 40 features selected\n",
      "Top 10: ['card2', 'D1_normalized', 'card1', 'C13_C1_ratio', 'addr1', 'D2_normalized', 'TransactionAmt', 'C2_C1_ratio', 'card5', 'C1']\n"
     ]
    }
   ],
   "source": [
    "# Scenario 5: Top 40 Features (from preprocessed data)\n",
    "# Train a quick LightGBM to get feature importance\n",
    "filtered_features = feature_lists['filtered_features']\n",
    "\n",
    "X_temp = train_preprocessed[filtered_features].fillna(-999)\n",
    "y_temp = train_preprocessed['isFraud']\n",
    "\n",
    "lgb_temp = LGBMClassifier(n_estimators=100, max_depth=6, random_state=42, verbose=-1)\n",
    "lgb_temp.fit(X_temp, y_temp)\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': filtered_features,\n",
    "    'importance': lgb_temp.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "top_40_features = importance_df.head(40)['feature'].tolist()\n",
    "\n",
    "print(f'Top 40 features selected')\n",
    "print(f'Top 10: {top_40_features[:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80dbfa4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SCENARIO 5: Top 40 Features\n",
      "Features: 40, Samples: 472432\n",
      "======================================================================\n",
      "  RandomForest: CV=0.9458+/-0.0009, Test=0.8961 (137.7s)\n",
      "  XGBoost: CV=0.9411+/-0.0004, Test=0.8951 (214.9s)\n",
      "  LightGBM: CV=0.9375+/-0.0012, Test=0.9008 (16.6s)\n",
      "  CatBoost: CV=0.9179+/-0.0020, Test=0.8885 (68.3s)\n",
      "  Stacking_Weighted: Test=0.9032\n",
      "  Stacking_MLP: Test=0.8952\n",
      "  Stacking_Blend: Test=0.8756\n",
      "  Rank_Average: Test=0.9028\n"
     ]
    }
   ],
   "source": [
    "# Run Scenario 5\n",
    "X_train_s5 = train_preprocessed[top_40_features].copy()\n",
    "X_test_s5 = test_preprocessed[top_40_features].copy()\n",
    "y_train_s5 = train_preprocessed['isFraud'].copy()\n",
    "y_test_s5 = test_preprocessed['isFraud'].copy()\n",
    "\n",
    "X_train_s5 = X_train_s5.replace([np.inf, -np.inf], np.nan).fillna(-999)\n",
    "X_test_s5 = X_test_s5.replace([np.inf, -np.inf], np.nan).fillna(-999)\n",
    "\n",
    "SCENARIOS[5] = {\n",
    "    'name': 'Top 40 Features',\n",
    "    'description': 'Top features by LightGBM importance',\n",
    "    'n_features': X_train_s5.shape[1]\n",
    "}\n",
    "\n",
    "results_s5 = run_scenario(5, SCENARIOS[5]['name'], X_train_s5, X_test_s5,\n",
    "                          y_train_s5, y_test_s5, scale_pos_weight, cat_indices=None)\n",
    "all_results.append(results_s5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e906878a",
   "metadata": {},
   "source": [
    "## 8. Results Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc5657f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================================================================\n",
      "MASTER RESULTS TABLE\n",
      "========================================================================================================================\n",
      " Scenario          Approach  CV_AUC_mean  CV_AUC_std  Test_AUC  Test_AP  Optimal_Threshold  Precision_opt  Recall_opt  F1_opt\n",
      "        1      RandomForest       0.9116      0.0016    0.8723   0.4567             0.3304         0.1251      0.7894  0.2159\n",
      "        1           XGBoost       0.9380      0.0009    0.9078   0.5140             0.3899         0.1602      0.8159  0.2678\n",
      "        1          LightGBM       0.9371      0.0007    0.9085   0.5162             0.3801         0.1502      0.8255  0.2541\n",
      "        1          CatBoost       0.9170      0.0007    0.8943   0.4693             0.4443         0.1494      0.7972  0.2516\n",
      "        1 Stacking_Weighted          NaN         NaN    0.9051   0.5122             0.3723         0.1466      0.8312  0.2492\n",
      "        1      Stacking_MLP          NaN         NaN    0.9069   0.5242             0.0257         0.1616      0.8041  0.2690\n",
      "        1    Stacking_Blend          NaN         NaN    0.8964   0.4921             0.3193         0.1557      0.8115  0.2612\n",
      "        1      Rank_Average          NaN         NaN    0.9021   0.5034             0.7924         0.1464      0.8184  0.2484\n",
      "        2      RandomForest       0.9000      0.0012    0.8413   0.2311             0.3486         0.1151      0.7443  0.1994\n",
      "        2           XGBoost       0.8939      0.0015    0.8413   0.2362             0.4694         0.1268      0.7104  0.2151\n",
      "        2          LightGBM       0.8888      0.0006    0.8441   0.2456             0.4957         0.1334      0.7089  0.2246\n",
      "        2          CatBoost       0.8687      0.0012    0.8211   0.2079             0.4086         0.0935      0.7670  0.1666\n",
      "        2 Stacking_Weighted          NaN         NaN    0.8449   0.2388             0.4227         0.1136      0.7490  0.1974\n",
      "        2      Stacking_MLP          NaN         NaN    0.8467   0.2353             0.0268         0.1174      0.7527  0.2031\n",
      "        2    Stacking_Blend          NaN         NaN    0.8428   0.2201             0.3235         0.1057      0.7699  0.1859\n",
      "        2      Rank_Average          NaN         NaN    0.8442   0.2346             0.7656         0.1175      0.7438  0.2030\n",
      "        3      RandomForest       0.9008      0.0012    0.8630   0.4418             0.3356         0.1159      0.7825  0.2018\n",
      "        3           XGBoost       0.9208      0.0013    0.8865   0.4888             0.3666         0.1508      0.7776  0.2527\n",
      "        3          LightGBM       0.9200      0.0014    0.8849   0.4852             0.4578         0.1655      0.7589  0.2717\n",
      "        3          CatBoost       0.9014      0.0016    0.8818   0.4528             0.4457         0.1377      0.7790  0.2341\n",
      "        3 Stacking_Weighted          NaN         NaN    0.8865   0.4827             0.3962         0.1451      0.7832  0.2449\n",
      "        3      Stacking_MLP          NaN         NaN    0.8745   0.4875             0.0201         0.1537      0.7537  0.2554\n",
      "        3    Stacking_Blend          NaN         NaN    0.8672   0.4564             0.3469         0.1467      0.7635  0.2461\n",
      "        3      Rank_Average          NaN         NaN    0.8838   0.4782             0.8171         0.1510      0.7628  0.2521\n",
      "        4      RandomForest       0.9036      0.0016    0.8356   0.2616             0.3571         0.1152      0.7286  0.1990\n",
      "        4           XGBoost       0.9058      0.0005    0.8460   0.2975             0.3410         0.1022      0.7785  0.1806\n",
      "        4          LightGBM       0.9026      0.0008    0.8519   0.3192             0.4827         0.1209      0.7367  0.2077\n",
      "        4          CatBoost       0.8788      0.0020    0.8291   0.2639             0.4510         0.0971      0.7630  0.1723\n",
      "        4 Stacking_Weighted          NaN         NaN    0.8494   0.3017             0.3896         0.1037      0.7763  0.1830\n",
      "        4      Stacking_MLP          NaN         NaN    0.8529   0.3049             0.0187         0.1167      0.7579  0.2023\n",
      "        4    Stacking_Blend          NaN         NaN    0.8343   0.2750             0.2985         0.1174      0.7131  0.2016\n",
      "        4      Rank_Average          NaN         NaN    0.8482   0.3010             0.7747         0.1187      0.7308  0.2042\n",
      "        5      RandomForest       0.9458      0.0009    0.8961   0.4797             0.2632         0.1480      0.8073  0.2502\n",
      "        5           XGBoost       0.9411      0.0004    0.8951   0.4823             0.2905         0.1353      0.8051  0.2317\n",
      "        5          LightGBM       0.9375      0.0012    0.9008   0.5013             0.3959         0.1412      0.8159  0.2407\n",
      "        5          CatBoost       0.9179      0.0020    0.8885   0.4699             0.4765         0.1497      0.7694  0.2507\n",
      "        5 Stacking_Weighted          NaN         NaN    0.9032   0.5036             0.3340         0.1378      0.8236  0.2361\n",
      "        5      Stacking_MLP          NaN         NaN    0.8952   0.4604             0.0184         0.1562      0.7756  0.2600\n",
      "        5    Stacking_Blend          NaN         NaN    0.8756   0.4871             0.2658         0.1528      0.7803  0.2556\n",
      "        5      Rank_Average          NaN         NaN    0.9028   0.5012             0.7967         0.1501      0.8002  0.2528\n"
     ]
    }
   ],
   "source": [
    "# Combine all results\n",
    "master_results = pd.concat(all_results, ignore_index=True)\n",
    "\n",
    "# Round for display\n",
    "numeric_cols = ['CV_AUC_mean', 'CV_AUC_std', 'Test_AUC', 'Test_AP',\n",
    "                'Optimal_Threshold', 'Precision_opt', 'Recall_opt', 'F1_opt']\n",
    "results_display = master_results.copy()\n",
    "for col in numeric_cols:\n",
    "    results_display[col] = results_display[col].round(4)\n",
    "\n",
    "print('\\n' + '='*120)\n",
    "print('MASTER RESULTS TABLE')\n",
    "print('='*120)\n",
    "print(results_display.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e5de1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================================================================\n",
      "RESULTS BY SCENARIO\n",
      "========================================================================================================================\n",
      "\n",
      "======================================================================\n",
      "Scenario 1 Results: Raw Data Baseline\n",
      "(No feature engineering, minimal preprocessing, 432 features)\n",
      "======================================================================\n",
      "         Approach  CV_AUC_mean  CV_AUC_std  Test_AUC  Test_AP  Optimal_Threshold  Precision_opt  Recall_opt  F1_opt\n",
      "         LightGBM       0.9371      0.0007    0.9085   0.5162             0.3801         0.1502      0.8255  0.2541\n",
      "          XGBoost       0.9380      0.0009    0.9078   0.5140             0.3899         0.1602      0.8159  0.2678\n",
      "     Stacking_MLP          NaN         NaN    0.9069   0.5242             0.0257         0.1616      0.8041  0.2690\n",
      "Stacking_Weighted          NaN         NaN    0.9051   0.5122             0.3723         0.1466      0.8312  0.2492\n",
      "     Rank_Average          NaN         NaN    0.9021   0.5034             0.7924         0.1464      0.8184  0.2484\n",
      "   Stacking_Blend          NaN         NaN    0.8964   0.4921             0.3193         0.1557      0.8115  0.2612\n",
      "         CatBoost       0.9170      0.0007    0.8943   0.4693             0.4443         0.1494      0.7972  0.2516\n",
      "     RandomForest       0.9116      0.0016    0.8723   0.4567             0.3304         0.1251      0.7894  0.2159\n",
      "\n",
      "Best: LightGBM (Test AUC: 0.9085)\n",
      "\n",
      "======================================================================\n",
      "Scenario 2 Results: High Cardinality Categorical\n",
      "(Raw categoricals with minimal encoding, 23 features)\n",
      "======================================================================\n",
      "         Approach  CV_AUC_mean  CV_AUC_std  Test_AUC  Test_AP  Optimal_Threshold  Precision_opt  Recall_opt  F1_opt\n",
      "     Stacking_MLP          NaN         NaN    0.8467   0.2353             0.0268         0.1174      0.7527  0.2031\n",
      "Stacking_Weighted          NaN         NaN    0.8449   0.2388             0.4227         0.1136      0.7490  0.1974\n",
      "     Rank_Average          NaN         NaN    0.8442   0.2346             0.7656         0.1175      0.7438  0.2030\n",
      "         LightGBM       0.8888      0.0006    0.8441   0.2456             0.4957         0.1334      0.7089  0.2246\n",
      "   Stacking_Blend          NaN         NaN    0.8428   0.2201             0.3235         0.1057      0.7699  0.1859\n",
      "     RandomForest       0.9000      0.0012    0.8413   0.2311             0.3486         0.1151      0.7443  0.1994\n",
      "          XGBoost       0.8939      0.0015    0.8413   0.2362             0.4694         0.1268      0.7104  0.2151\n",
      "         CatBoost       0.8687      0.0012    0.8211   0.2079             0.4086         0.0935      0.7670  0.1666\n",
      "\n",
      "Best: Stacking_MLP (Test AUC: 0.8467)\n",
      "\n",
      "======================================================================\n",
      "Scenario 3 Results: Numerical Only\n",
      "(No categorical features, pure numerical, 395 features)\n",
      "======================================================================\n",
      "         Approach  CV_AUC_mean  CV_AUC_std  Test_AUC  Test_AP  Optimal_Threshold  Precision_opt  Recall_opt  F1_opt\n",
      "          XGBoost       0.9208      0.0013    0.8865   0.4888             0.3666         0.1508      0.7776  0.2527\n",
      "Stacking_Weighted          NaN         NaN    0.8865   0.4827             0.3962         0.1451      0.7832  0.2449\n",
      "         LightGBM       0.9200      0.0014    0.8849   0.4852             0.4578         0.1655      0.7589  0.2717\n",
      "     Rank_Average          NaN         NaN    0.8838   0.4782             0.8171         0.1510      0.7628  0.2521\n",
      "         CatBoost       0.9014      0.0016    0.8818   0.4528             0.4457         0.1377      0.7790  0.2341\n",
      "     Stacking_MLP          NaN         NaN    0.8745   0.4875             0.0201         0.1537      0.7537  0.2554\n",
      "   Stacking_Blend          NaN         NaN    0.8672   0.4564             0.3469         0.1467      0.7635  0.2461\n",
      "     RandomForest       0.9008      0.0012    0.8630   0.4418             0.3356         0.1159      0.7825  0.2018\n",
      "\n",
      "Best: XGBoost (Test AUC: 0.8865)\n",
      "\n",
      "======================================================================\n",
      "Scenario 4 Results: Amnesiac System\n",
      "(No C/D/V columns - real-time only data, 64 features)\n",
      "======================================================================\n",
      "         Approach  CV_AUC_mean  CV_AUC_std  Test_AUC  Test_AP  Optimal_Threshold  Precision_opt  Recall_opt  F1_opt\n",
      "     Stacking_MLP          NaN         NaN    0.8529   0.3049             0.0187         0.1167      0.7579  0.2023\n",
      "         LightGBM       0.9026      0.0008    0.8519   0.3192             0.4827         0.1209      0.7367  0.2077\n",
      "Stacking_Weighted          NaN         NaN    0.8494   0.3017             0.3896         0.1037      0.7763  0.1830\n",
      "     Rank_Average          NaN         NaN    0.8482   0.3010             0.7747         0.1187      0.7308  0.2042\n",
      "          XGBoost       0.9058      0.0005    0.8460   0.2975             0.3410         0.1022      0.7785  0.1806\n",
      "     RandomForest       0.9036      0.0016    0.8356   0.2616             0.3571         0.1152      0.7286  0.1990\n",
      "   Stacking_Blend          NaN         NaN    0.8343   0.2750             0.2985         0.1174      0.7131  0.2016\n",
      "         CatBoost       0.8788      0.0020    0.8291   0.2639             0.4510         0.0971      0.7630  0.1723\n",
      "\n",
      "Best: Stacking_MLP (Test AUC: 0.8529)\n",
      "\n",
      "======================================================================\n",
      "Scenario 5 Results: Top 40 Features\n",
      "(Top features by LightGBM importance, 40 features)\n",
      "======================================================================\n",
      "         Approach  CV_AUC_mean  CV_AUC_std  Test_AUC  Test_AP  Optimal_Threshold  Precision_opt  Recall_opt  F1_opt\n",
      "Stacking_Weighted          NaN         NaN    0.9032   0.5036             0.3340         0.1378      0.8236  0.2361\n",
      "     Rank_Average          NaN         NaN    0.9028   0.5012             0.7967         0.1501      0.8002  0.2528\n",
      "         LightGBM       0.9375      0.0012    0.9008   0.5013             0.3959         0.1412      0.8159  0.2407\n",
      "     RandomForest       0.9458      0.0009    0.8961   0.4797             0.2632         0.1480      0.8073  0.2502\n",
      "     Stacking_MLP          NaN         NaN    0.8952   0.4604             0.0184         0.1562      0.7756  0.2600\n",
      "          XGBoost       0.9411      0.0004    0.8951   0.4823             0.2905         0.1353      0.8051  0.2317\n",
      "         CatBoost       0.9179      0.0020    0.8885   0.4699             0.4765         0.1497      0.7694  0.2507\n",
      "   Stacking_Blend          NaN         NaN    0.8756   0.4871             0.2658         0.1528      0.7803  0.2556\n",
      "\n",
      "Best: Stacking_Weighted (Test AUC: 0.9032)\n"
     ]
    }
   ],
   "source": [
    "# Per-scenario tables\n",
    "scenario_results_dict = {}\n",
    "\n",
    "print('\\n' + '='*120)\n",
    "print('RESULTS BY SCENARIO')\n",
    "print('='*120)\n",
    "\n",
    "for sid in sorted(SCENARIOS.keys()):\n",
    "    scenario_df = results_display[results_display['Scenario'] == sid].copy()\n",
    "    scenario_df = scenario_df.drop(columns=['Scenario'])\n",
    "    scenario_df = scenario_df.sort_values('Test_AUC', ascending=False).reset_index(drop=True)\n",
    "    scenario_results_dict[sid] = scenario_df\n",
    "    \n",
    "    print(f'\\n{\"=\"*70}')\n",
    "    print(f'Scenario {sid} Results: {SCENARIOS[sid][\"name\"]}')\n",
    "    print(f'({SCENARIOS[sid][\"description\"]}, {SCENARIOS[sid][\"n_features\"]} features)')\n",
    "    print('='*70)\n",
    "    print(scenario_df.to_string(index=False))\n",
    "    \n",
    "    best = scenario_df.iloc[0]\n",
    "    print(f'\\nBest: {best[\"Approach\"]} (Test AUC: {best[\"Test_AUC\"]:.4f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61afb9a",
   "metadata": {},
   "source": [
    "## 9. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "795e1b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\Abdulkadir\\Desktop\\Uygulama almalar\\Fraud_Detection\\Fraud_Detection\\results\\Scenario_Tests_2\\results_master.csv\n",
      "Saved: c:\\Users\\Abdulkadir\\Desktop\\Uygulama almalar\\Fraud_Detection\\Fraud_Detection\\results\\Scenario_Tests_2\\results_by_scenario.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Create output directory\n",
    "results_dir = ROOT / 'results' / 'Scenario_Tests_2'\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save CSV\n",
    "csv_path = results_dir / 'results_master.csv'\n",
    "results_display.to_csv(csv_path, index=False)\n",
    "print(f'Saved: {csv_path}')\n",
    "\n",
    "# Save Excel\n",
    "excel_path = results_dir / 'results_by_scenario.xlsx'\n",
    "with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n",
    "    results_display.to_excel(writer, sheet_name='Master', index=False)\n",
    "    for sid, sdf in scenario_results_dict.items():\n",
    "        sdf.to_excel(writer, sheet_name=f'Scenario_{sid}', index=False)\n",
    "\n",
    "print(f'Saved: {excel_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "185f9cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "SCENARIO SUMMARY\n",
      "====================================================================================================\n",
      " Scenario                         Name  Features        Best_Model  Test_AUC  Test_AP\n",
      "        1            Raw Data Baseline       432          LightGBM    0.9085   0.5162\n",
      "        2 High Cardinality Categorical        23      Stacking_MLP    0.8467   0.2353\n",
      "        3               Numerical Only       395 Stacking_Weighted    0.8865   0.4827\n",
      "        4              Amnesiac System        64      Stacking_MLP    0.8529   0.3049\n",
      "        5              Top 40 Features        40 Stacking_Weighted    0.9032   0.5036\n",
      "\n",
      "Results saved to: c:\\Users\\Abdulkadir\\Desktop\\Uygulama almalar\\Fraud_Detection\\Fraud_Detection\\results\\Scenario_Tests_2\n"
     ]
    }
   ],
   "source": [
    "# Summary table\n",
    "print('\\n' + '='*100)\n",
    "print('SCENARIO SUMMARY')\n",
    "print('='*100)\n",
    "\n",
    "summary_rows = []\n",
    "for sid in sorted(SCENARIOS.keys()):\n",
    "    sdf = master_results[master_results['Scenario'] == sid]\n",
    "    best = sdf.loc[sdf['Test_AUC'].idxmax()]\n",
    "    summary_rows.append({\n",
    "        'Scenario': sid,\n",
    "        'Name': SCENARIOS[sid]['name'],\n",
    "        'Features': SCENARIOS[sid]['n_features'],\n",
    "        'Best_Model': best['Approach'],\n",
    "        'Test_AUC': round(best['Test_AUC'], 4),\n",
    "        'Test_AP': round(best['Test_AP'], 4)\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Save summary\n",
    "summary_df.to_csv(results_dir / 'scenario_summary.csv', index=False)\n",
    "print(f'\\nResults saved to: {results_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0cc38935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario details saved\n"
     ]
    }
   ],
   "source": [
    "# Save scenario details\n",
    "details = '''Scenario Tests 2 - Experiment Documentation\n",
    "================================================\n",
    "\n",
    "Purpose: Creative scenarios to highlight different model strengths\n",
    "\n",
    "ENSEMBLE METHODS\n",
    "----------------\n",
    "1. Stacking_Weighted: CV-AUC weighted average of base models\n",
    "2. Stacking_MLP: Neural network meta-learner (16,8 hidden layers)\n",
    "3. Stacking_Blend: Holdout-based blending with LogisticRegression\n",
    "4. Rank_Average: Calibration-free rank averaging\n",
    "\n",
    "SCENARIOS\n",
    "---------\n",
    "Scenario 1: Raw Data Baseline\n",
    "- No feature engineering, minimal preprocessing\n",
    "- Purpose: Establish \"before\" state\n",
    "\n",
    "Scenario 2: High Cardinality Categorical\n",
    "- Raw categoricals with minimal encoding\n",
    "- Purpose: Test native categorical handling\n",
    "\n",
    "Scenario 3: Numerical Only\n",
    "- No categorical features\n",
    "- Purpose: Test pure numerical optimization\n",
    "\n",
    "Scenario 4: Amnesiac System\n",
    "- No C/D/V columns (historical data)\n",
    "- Purpose: Prove value of data engineering\n",
    "- Story: Real-time fraud detection without database access\n",
    "\n",
    "Scenario 5: Top 40 Features\n",
    "- Top features by LightGBM importance\n",
    "- Purpose: Test generalization with limited features\n",
    "\n",
    "EVALUATION\n",
    "----------\n",
    "- CV: StratifiedKFold, n_splits=3, shuffle=True, random_state=42\n",
    "- Metrics: CV AUC, Test AUC, Test AP, Youden threshold, Precision/Recall/F1\n",
    "'''\n",
    "\n",
    "with open(results_dir / 'scenario_details.txt', 'w') as f:\n",
    "    f.write(details)\n",
    "\n",
    "print('Scenario details saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
