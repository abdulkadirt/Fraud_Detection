{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76803c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "ROOT = Path.cwd().parent\n",
    "DATA = ROOT / \"data\"\n",
    "sys.path.append(str(ROOT / \"functions\"))\n",
    "\n",
    "from categoric_functions import *\n",
    "from numeric_functions import *\n",
    "\n",
    "print(\"Libraries imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69da654",
   "metadata": {},
   "source": [
    "## 1. Load Training Data (for fitting encoders) and Kaggle Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6e1cff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (590540, 434)\n",
      "Kaggle Test shape: (506691, 433)\n"
     ]
    }
   ],
   "source": [
    "# Load FULL training data (not the split version)\n",
    "train_path = DATA / \"train_merged.csv\"\n",
    "train_df = pd.read_csv(train_path, low_memory=False)\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "\n",
    "# Load Kaggle test data\n",
    "test_path = DATA / \"test_merged.csv\"\n",
    "kaggle_test = pd.read_csv(test_path, low_memory=False)\n",
    "print(f\"Kaggle Test shape: {kaggle_test.shape}\")\n",
    "\n",
    "# Save TransactionID for submission\n",
    "submission_ids = kaggle_test['TransactionID'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f9119f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage decreased to 645.97 Mb (67.0% reduction)\n",
      "Memory usage decreased to 561.50 Mb (66.5% reduction)\n"
     ]
    }
   ],
   "source": [
    "# Reduce memory\n",
    "train_df = reduce_mem_usage(train_df)\n",
    "kaggle_test = reduce_mem_usage(kaggle_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d85089",
   "metadata": {},
   "source": [
    "## 2. Apply Same Preprocessing Pipeline as EDA.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc3c03cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 414 columns with missing values.\n",
      "There are 9 columns with missing percent > 95%\n",
      "Dropped 9 high-missing columns\n",
      "Train: (590540, 425), Test: (506691, 433)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Step 1: Drop high missing columns (>95%)\n",
    "# =============================================================================\n",
    "threshold = 95\n",
    "high_missing = top_missing_cols(train_df, thresh=threshold)\n",
    "cols_to_drop = high_missing[high_missing['missing_percent'] > threshold]['col'].tolist()\n",
    "\n",
    "train_df = train_df.drop(columns=cols_to_drop)\n",
    "kaggle_test = kaggle_test.drop(columns=[c for c in cols_to_drop if c in kaggle_test.columns])\n",
    "\n",
    "print(f\"Dropped {len(cols_to_drop)} high-missing columns\")\n",
    "print(f\"Train: {train_df.shape}, Test: {kaggle_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32e06cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical engineering complete!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Step 2: Categorical Engineering Pipeline\n",
    "# =============================================================================\n",
    "def apply_categorical_engineering(df, rare_maps=None):\n",
    "    df = df.copy()\n",
    "    df, rare_maps = encode_rare_categories(\n",
    "        df, \n",
    "        columns={'card3': 200, 'card5': 300},\n",
    "        rare_maps=rare_maps\n",
    "    )\n",
    "    df = (df\n",
    "        .pipe(clean_email_domains)\n",
    "        .pipe(create_email_match)\n",
    "        .pipe(consolidate_device_info)\n",
    "        .pipe(extract_screen_features)\n",
    "    )\n",
    "    return df, rare_maps\n",
    "\n",
    "# Apply - learn from train, apply to test\n",
    "train_df, rare_maps = apply_categorical_engineering(train_df, rare_maps=None)\n",
    "kaggle_test, _ = apply_categorical_engineering(kaggle_test, rare_maps=rare_maps)\n",
    "\n",
    "print(\"Categorical engineering complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c399031b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning 171 feature pairs...\n",
      "Progress: 100/171 pairs processed...\n",
      "\n",
      "Analysis complete! Found 171 valid combinations.\n",
      "Top fraud rate: 97.6%\n",
      "Created 20 interaction features\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Step 3: Interaction Features (use same pairs as EDA)\n",
    "# =============================================================================\n",
    "categorical_to_scan = [\n",
    "    'P_emaildomain_bin', 'R_emaildomain_bin', 'email_match', 'OS_type', 'Device_name',\n",
    "    'card5', 'card3', 'card6', 'card4', 'ProductCD', 'DeviceType', \n",
    "    'screen_width', 'screen_height', 'total_pixels', 'aspect_ratio',\n",
    "    'id_28', 'id_20', 'id_15', 'id_19'\n",
    "]\n",
    "\n",
    "# Scan on train to identify interactions\n",
    "top_combos = scan_all_bivariate_combinations(\n",
    "    train_df, \n",
    "    feature_list=[c for c in categorical_to_scan if c in train_df.columns],\n",
    "    target='isFraud',\n",
    "    min_samples=50,\n",
    "    top_n=20\n",
    ")\n",
    "\n",
    "interactions = [(row['feature1'], row['feature2']) for _, row in top_combos.iterrows()]\n",
    "\n",
    "train_df = create_interaction_features(train_df, interactions)\n",
    "kaggle_test = create_interaction_features(kaggle_test, interactions)\n",
    "\n",
    "print(f\"Created {len(interactions)} interaction features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caded1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped original transformed columns\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Step 4: Drop transformed columns\n",
    "# =============================================================================\n",
    "drop_cols = ['P_emaildomain', 'R_emaildomain', 'id_30', 'DeviceInfo', 'id_33']\n",
    "train_df = train_df.drop(columns=drop_cols, errors='ignore')\n",
    "kaggle_test = kaggle_test.drop(columns=drop_cols, errors='ignore')\n",
    "\n",
    "print(\"Dropped original transformed columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ded9b9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded 22 high-card and 29 low-card features\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Step 5: Encoding\n",
    "# =============================================================================\n",
    "# Define categorical features\n",
    "categorical_features = [\n",
    "    'ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5', 'card6',\n",
    "    'addr1', 'addr2', 'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9',\n",
    "    'DeviceType', 'id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18', \n",
    "    'id_19', 'id_20', 'id_21', 'id_22', 'id_23', 'id_24', 'id_25', 'id_26', \n",
    "    'id_27', 'id_28', 'id_29', 'id_31', 'id_32', 'id_34', 'id_35', 'id_36', \n",
    "    'id_37', 'id_38', 'P_emaildomain_bin', 'R_emaildomain_bin', 'email_match',\n",
    "    'OS_type', 'Device_name'\n",
    "]\n",
    "\n",
    "# Add interaction features\n",
    "interaction_cols = [c for c in train_df.columns if c.startswith('inter_')]\n",
    "categorical_features.extend(interaction_cols)\n",
    "\n",
    "# Get object columns that are categorical\n",
    "object_columns = [col for col in train_df.select_dtypes(include=['object']).columns \n",
    "                  if col in categorical_features]\n",
    "\n",
    "cardinality_threshold = 15\n",
    "low_card = [col for col in object_columns if train_df[col].nunique() <= cardinality_threshold]\n",
    "high_card = [col for col in object_columns if train_df[col].nunique() > cardinality_threshold]\n",
    "\n",
    "# Frequency encoding for high cardinality\n",
    "train_df, freq_maps = apply_frequency_encoding(train_df, high_card, normalize=True)\n",
    "kaggle_test, _ = apply_frequency_encoding(kaggle_test, high_card, freq_dict=freq_maps)\n",
    "\n",
    "# Label encoding for low cardinality\n",
    "train_df, label_encoders = apply_label_encoding(train_df, low_card)\n",
    "kaggle_test, _ = apply_label_encoding(kaggle_test, low_card, encoder_dict=label_encoders)\n",
    "\n",
    "print(f\"Encoded {len(high_card)} high-card and {len(low_card)} low-card features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ddea181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V columns reduced: 339 -> 15\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Step 6: V-column reduction\n",
    "# =============================================================================\n",
    "v_cols = [col for col in train_df.columns if col.startswith('V')]\n",
    "\n",
    "v_pattern_groups = group_by_missing_pattern(train_df, v_cols)\n",
    "representative_v = []\n",
    "\n",
    "for pattern_id, info in v_pattern_groups.items():\n",
    "    group_cols = info['columns']\n",
    "    if len(group_cols) == 1:\n",
    "        representative_v.extend(group_cols)\n",
    "        continue\n",
    "    ks_res = test_feature_discrimination(train_df, group_cols, test='ks')\n",
    "    if not ks_res.empty:\n",
    "        representative_v.append(ks_res.iloc[0]['Feature'])\n",
    "\n",
    "# Filter V columns\n",
    "cols_to_keep = train_df.columns.difference(v_cols).union(pd.Index(representative_v))\n",
    "train_df = train_df[cols_to_keep]\n",
    "kaggle_test = kaggle_test[[c for c in cols_to_keep if c in kaggle_test.columns]]\n",
    "\n",
    "print(f\"V columns reduced: {len(v_cols)} -> {len(representative_v)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20c40328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical engineering complete!\n",
      "Train: (590540, 162), Test: (506691, 110)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Step 7: Numerical Feature Engineering\n",
    "# =============================================================================\n",
    "# Time features\n",
    "train_df = convert_dt_to_day(train_df)\n",
    "kaggle_test = convert_dt_to_day(kaggle_test)\n",
    "\n",
    "# UID creation\n",
    "train_df = create_uid(train_df, uid_cols=['card1', 'addr1', 'D1'])\n",
    "kaggle_test = create_uid(kaggle_test, uid_cols=['card1', 'addr1', 'D1'])\n",
    "\n",
    "# Normalize D columns\n",
    "train_df = normalize_d_columns(train_df)\n",
    "kaggle_test = normalize_d_columns(kaggle_test)\n",
    "\n",
    "# Amount features\n",
    "train_df = extract_amt_decimal(train_df)\n",
    "kaggle_test = extract_amt_decimal(kaggle_test)\n",
    "\n",
    "# Log transform\n",
    "train_df['TransactionAmt_log'] = np.log1p(train_df['TransactionAmt'])\n",
    "kaggle_test['TransactionAmt_log'] = np.log1p(kaggle_test['TransactionAmt'])\n",
    "\n",
    "# C velocity features\n",
    "train_df = create_c_velocity_features(train_df)\n",
    "kaggle_test = create_c_velocity_features(kaggle_test)\n",
    "\n",
    "# UID aggregations\n",
    "train_df, uid_agg_maps = create_uid_aggregations(train_df, uid_col='uid')\n",
    "kaggle_test, _ = create_uid_aggregations(kaggle_test, uid_col='uid', agg_maps=uid_agg_maps)\n",
    "\n",
    "print(\"Numerical engineering complete!\")\n",
    "print(f\"Train: {train_df.shape}, Test: {kaggle_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc8900fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 248 filtered features\n",
      "\n",
      "⚠️ Features missing in test: ['V222', 'V11', 'D12_is_null', 'D2_D3_diff', 'D8_is_null', 'D9_is_null', 'D6_is_null', 'D14_is_null', 'D_null_count', 'D13_is_null', 'id_01', 'D11_is_null', 'D7_is_null', 'D2_D3_ratio', 'D10_D15_ratio', 'screen_height', 'total_pixels', 'screen_width', 'aspect_ratio', 'D2_is_null', 'D1_D4_ratio', 'id_06', 'id_02', 'D3_is_null', 'id_05', 'D1_D2_ratio', 'D10_is_null', 'D10_D15_diff', 'D15_is_null', 'D5_is_null', 'id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18', 'id_19', 'id_20', 'id_28', 'id_29', 'id_31', 'id_32', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38', 'OS_type', 'inter_card3_x_id_19', 'inter_R_emaildomain_bin_x_aspect_ratio', 'inter_R_emaildomain_bin_x_screen_height', 'inter_R_emaildomain_bin_x_total_pixels', 'inter_ProductCD_x_aspect_ratio', 'inter_ProductCD_x_total_pixels', 'inter_ProductCD_x_screen_height', 'inter_P_emaildomain_bin_x_screen_height', 'inter_P_emaildomain_bin_x_total_pixels', 'inter_P_emaildomain_bin_x_aspect_ratio', 'inter_P_emaildomain_bin_x_id_19', 'inter_R_emaildomain_bin_x_id_19', 'inter_aspect_ratio_x_id_28', 'inter_aspect_ratio_x_id_15', 'inter_email_match_x_screen_width', 'inter_email_match_x_total_pixels', 'inter_id_20_x_id_19', 'inter_total_pixels_x_id_28', 'inter_screen_height_x_id_15', 'inter_card6_x_total_pixels', 'inter_card6_x_screen_width', 'inter_total_pixels_x_id_15', 'inter_screen_height_x_id_20', 'inter_screen_height_x_id_28', 'inter_aspect_ratio_x_id_20', 'inter_card6_x_aspect_ratio', 'inter_email_match_x_screen_height', 'inter_total_pixels_x_id_20', 'inter_card6_x_screen_height', 'inter_Device_name_x_screen_width', 'inter_Device_name_x_total_pixels', 'inter_Device_name_x_DeviceType', 'inter_Device_name_x_id_19', 'inter_Device_name_x_screen_height', 'inter_card3_x_id_20', 'inter_email_match_x_aspect_ratio', 'inter_P_emaildomain_bin_x_screen_width', 'inter_Device_name_x_aspect_ratio', 'inter_id_20_x_id_15', 'inter_OS_type_x_aspect_ratio', 'inter_OS_type_x_total_pixels', 'inter_DeviceType_x_aspect_ratio', 'inter_OS_type_x_screen_height', 'inter_DeviceType_x_screen_height', 'inter_card5_x_id_19', 'inter_id_15_x_id_19', 'inter_card5_x_id_20', 'inter_id_28_x_id_19', 'inter_id_28_x_id_20', 'inter_screen_width_x_screen_height', 'inter_total_pixels_x_aspect_ratio', 'inter_screen_height_x_aspect_ratio', 'inter_screen_height_x_total_pixels', 'inter_screen_width_x_total_pixels', 'inter_screen_width_x_aspect_ratio', 'inter_R_emaildomain_bin_x_id_20', 'inter_P_emaildomain_bin_x_id_20', 'inter_Device_name_x_id_20', 'inter_card3_x_aspect_ratio', 'inter_DeviceType_x_total_pixels', 'inter_total_pixels_x_id_19', 'inter_screen_width_x_id_19', 'inter_card3_x_ProductCD', 'inter_R_emaildomain_bin_x_Device_name', 'inter_card3_x_screen_height', 'inter_P_emaildomain_bin_x_Device_name', 'inter_card4_x_aspect_ratio', 'inter_card4_x_screen_height', 'inter_card6_x_id_19', 'inter_email_match_x_id_19', 'inter_card6_x_id_20', 'inter_card3_x_total_pixels', 'inter_ProductCD_x_id_19', 'inter_card4_x_total_pixels', 'inter_DeviceType_x_id_20', 'inter_card4_x_id_19', 'inter_OS_type_x_id_19', 'inter_screen_width_x_id_20', 'inter_email_match_x_id_20', 'inter_ProductCD_x_id_20', 'inter_OS_type_x_id_20', 'inter_DeviceType_x_id_19', 'inter_card4_x_id_20', 'inter_aspect_ratio_x_id_19', 'inter_OS_type_x_screen_width', 'inter_card5_x_total_pixels', 'inter_card5_x_screen_width', 'inter_Device_name_x_card5', 'inter_card5_x_screen_height', 'inter_screen_width_x_id_15', 'inter_screen_height_x_id_19', 'inter_ProductCD_x_screen_width', 'inter_P_emaildomain_bin_x_card3', 'inter_R_emaildomain_bin_x_screen_width', 'inter_OS_type_x_card3', 'inter_card3_x_screen_width', 'inter_DeviceType_x_screen_width', 'inter_Device_name_x_ProductCD', 'inter_screen_width_x_id_28']\n",
      "Using 100 available features\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Step 8: Load filtered_features from saved pickle\n",
    "# =============================================================================\n",
    "with open(DATA / \"feature_lists.pkl\", 'rb') as f:\n",
    "    feature_lists = pickle.load(f)\n",
    "\n",
    "filtered_features = feature_lists['filtered_features']\n",
    "print(f\"Using {len(filtered_features)} filtered features\")\n",
    "\n",
    "# Check which features are available in both datasets\n",
    "available_features = [f for f in filtered_features if f in train_df.columns and f in kaggle_test.columns]\n",
    "missing_in_test = [f for f in filtered_features if f not in kaggle_test.columns]\n",
    "\n",
    "if missing_in_test:\n",
    "    print(f\"\\n⚠️ Features missing in test: {missing_in_test}\")\n",
    "    print(f\"Using {len(available_features)} available features\")\n",
    "else:\n",
    "    print(f\"\\n✅ All {len(filtered_features)} features available!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1020409",
   "metadata": {},
   "source": [
    "## 3. Train LightGBM on Full Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "145a8a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (590540, 100)\n",
      "X_kaggle_test: (506691, 100)\n",
      "Training fraud rate: 3.50%\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Prepare data\n",
    "X_train = train_df[available_features].copy()\n",
    "y_train = train_df['isFraud'].copy()\n",
    "X_kaggle_test = kaggle_test[available_features].copy()\n",
    "\n",
    "# Handle missing values\n",
    "MISSING_FLAG = -999\n",
    "X_train = X_train.fillna(MISSING_FLAG)\n",
    "X_kaggle_test = X_kaggle_test.fillna(MISSING_FLAG)\n",
    "\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"X_kaggle_test: {X_kaggle_test.shape}\")\n",
    "print(f\"Training fraud rate: {y_train.mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ba62d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LightGBM on full training data...\n",
      "✅ Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Train LightGBM\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "\n",
    "lgb_model = LGBMClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=31,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "print(\"Training LightGBM on full training data...\")\n",
    "lgb_model.fit(X_train, y_train)\n",
    "print(\"✅ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45a8d02",
   "metadata": {},
   "source": [
    "## 4. Generate Predictions and Create Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3783e4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions shape: (506691,)\n",
      "Prediction stats:\n",
      "  Min: 0.0001\n",
      "  Max: 0.9993\n",
      "  Mean: 0.1955\n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities\n",
    "predictions = lgb_model.predict_proba(X_kaggle_test)[:, 1]\n",
    "\n",
    "print(f\"Predictions shape: {predictions.shape}\")\n",
    "print(f\"Prediction stats:\")\n",
    "print(f\"  Min: {predictions.min():.4f}\")\n",
    "print(f\"  Max: {predictions.max():.4f}\")\n",
    "print(f\"  Mean: {predictions.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "824e2e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Submission file saved to: c:\\Users\\Abdulkadir\\Desktop\\Uygulama çalışmaları\\Fraud_Detection\\Fraud_Detection\\data\\submission.csv\n",
      "\n",
      "Submission preview:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TransactionID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "isFraud",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "d96f93ad-aec3-4766-9ea0-9083ca883837",
       "rows": [
        [
         "0",
         "3663549",
         "0.017907624723128974"
        ],
        [
         "1",
         "3663550",
         "0.06252298512586289"
        ],
        [
         "2",
         "3663551",
         "0.1079896894981017"
        ],
        [
         "3",
         "3663552",
         "0.10591226671078292"
        ],
        [
         "4",
         "3663553",
         "0.052181657413014795"
        ],
        [
         "5",
         "3663554",
         "0.20687846843270627"
        ],
        [
         "6",
         "3663555",
         "0.2842341785362693"
        ],
        [
         "7",
         "3663556",
         "0.17387338671161084"
        ],
        [
         "8",
         "3663557",
         "0.024254030436411805"
        ],
        [
         "9",
         "3663558",
         "0.20112595215268142"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3663549</td>\n",
       "      <td>0.017908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3663550</td>\n",
       "      <td>0.062523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3663551</td>\n",
       "      <td>0.107990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3663552</td>\n",
       "      <td>0.105912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3663553</td>\n",
       "      <td>0.052182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3663554</td>\n",
       "      <td>0.206878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3663555</td>\n",
       "      <td>0.284234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3663556</td>\n",
       "      <td>0.173873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3663557</td>\n",
       "      <td>0.024254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3663558</td>\n",
       "      <td>0.201126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID   isFraud\n",
       "0        3663549  0.017908\n",
       "1        3663550  0.062523\n",
       "2        3663551  0.107990\n",
       "3        3663552  0.105912\n",
       "4        3663553  0.052182\n",
       "5        3663554  0.206878\n",
       "6        3663555  0.284234\n",
       "7        3663556  0.173873\n",
       "8        3663557  0.024254\n",
       "9        3663558  0.201126"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape: (506691, 2)\n"
     ]
    }
   ],
   "source": [
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    'TransactionID': submission_ids,\n",
    "    'isFraud': predictions\n",
    "})\n",
    "\n",
    "# Save submission\n",
    "submission_path = DATA / \"submission.csv\"\n",
    "submission.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"✅ Submission file saved to: {submission_path}\")\n",
    "print(f\"\\nSubmission preview:\")\n",
    "display(submission.head(10))\n",
    "print(f\"\\nShape: {submission.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
